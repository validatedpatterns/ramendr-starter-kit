#!/bin/bash
set -euo pipefail

echo "Starting ODF SSL certificate precheck and distribution..."
echo "This job ensures certificates are properly distributed before DR policies are applied"

# Configuration
MIN_CERTIFICATES=15
MIN_BUNDLE_SIZE=20000
MAX_ATTEMPTS=120  
SLEEP_INTERVAL=30
CLUSTER_READINESS_MAX_ATTEMPTS=120  # Wait up to 60 minutes for clusters to be ready (120 * 30s)
CLUSTER_READINESS_SLEEP=30

# Function to clean up placeholder ConfigMaps
cleanup_placeholder_configmaps() {
  echo "üßπ Cleaning up placeholder ConfigMaps from managed clusters..."
  
  MANAGED_CLUSTERS=$(oc get managedclusters -o jsonpath='{.items[*].metadata.name}' 2>/dev/null || echo "")
  
  if [[ -z "$MANAGED_CLUSTERS" ]]; then
    echo "No managed clusters found"
    return 1
  fi
  
  for cluster in $MANAGED_CLUSTERS; do
    if [[ "$cluster" == "local-cluster" ]]; then
      continue
    fi
    
    echo "Checking $cluster for placeholder ConfigMaps..."
    
    KUBECONFIG_FILE=""
    if oc get secret -n "$cluster" -o name | grep -E "(admin-kubeconfig|kubeconfig)" | head -1 | xargs -I {} oc get {} -n "$cluster" -o jsonpath='{.data.kubeconfig}' | base64 -d > "/tmp/${cluster}-kubeconfig.yaml" 2>/dev/null; then
      KUBECONFIG_FILE="/tmp/${cluster}-kubeconfig.yaml"
    fi
    
    if [[ -n "$KUBECONFIG_FILE" && -f "$KUBECONFIG_FILE" ]]; then
      configmap_content=$(oc --kubeconfig="$KUBECONFIG_FILE" get configmap cluster-proxy-ca-bundle -n openshift-config -o jsonpath='{.data.ca-bundle\.crt}' 2>/dev/null || echo "")
      
      if [[ "$configmap_content" == *"Placeholder for ODF SSL certificate bundle"* ]] || [[ "$configmap_content" == *"This will be populated by the certificate extraction job"* ]]; then
        echo "  üóëÔ∏è  Deleting placeholder ConfigMap from $cluster..."
        oc --kubeconfig="$KUBECONFIG_FILE" delete configmap cluster-proxy-ca-bundle -n openshift-config --ignore-not-found=true
        echo "  ‚úÖ Placeholder ConfigMap removed from $cluster"
      else
        echo "  ‚úÖ $cluster: No placeholder ConfigMap found"
      fi
    else
      echo "  ‚ùå $cluster: Could not get kubeconfig for cleanup"
    fi
  done
  
  echo "‚úÖ Placeholder ConfigMap cleanup completed"
  return 0
}

# Function to wait for required clusters to be available and joined
wait_for_cluster_readiness() {
  echo "üîç Waiting for required clusters (ocp-primary and ocp-secondary) to be available and joined..."
  echo "   This may take several minutes during initial cluster deployment"
  
  REQUIRED_CLUSTERS=("ocp-primary" "ocp-secondary")
  attempt=1
  
  while [[ $attempt -le $CLUSTER_READINESS_MAX_ATTEMPTS ]]; do
    echo "=== Cluster Readiness Check Attempt $attempt/$CLUSTER_READINESS_MAX_ATTEMPTS ==="
    
    all_ready=true
    unready_clusters=()
    
    for cluster in "${REQUIRED_CLUSTERS[@]}"; do
      # Check if cluster exists
      if ! oc get managedcluster "$cluster" &>/dev/null; then
        echo "  ‚è≥ Cluster $cluster does not exist yet..."
        all_ready=false
        unready_clusters+=("$cluster")
        continue
      fi
      
      # Check if cluster is available
      cluster_status=$(oc get managedcluster "$cluster" -o jsonpath='{.status.conditions[?(@.type=="ManagedClusterConditionAvailable")].status}' 2>/dev/null || echo "Unknown")
      if [[ "$cluster_status" != "True" ]]; then
        echo "  ‚è≥ Cluster $cluster is not available yet (status: $cluster_status)"
        all_ready=false
        unready_clusters+=("$cluster")
        continue
      fi
      
      # Check if cluster is joined
      joined_status=$(oc get managedcluster "$cluster" -o jsonpath='{.status.conditions[?(@.type=="ManagedClusterJoined")].status}' 2>/dev/null || echo "Unknown")
      if [[ "$joined_status" != "True" ]]; then
        echo "  ‚è≥ Cluster $cluster is not joined yet (status: $joined_status)"
        all_ready=false
        unready_clusters+=("$cluster")
        continue
      fi
      
      echo "  ‚úÖ Cluster $cluster is available and joined"
    done
    
    if [[ "$all_ready" == "true" ]]; then
      echo "‚úÖ All required clusters are available and joined!"
      return 0
    else
      echo "‚è≥ Waiting for clusters to be ready: ${unready_clusters[*]}"
      echo "   This is normal during initial cluster deployment - clusters may take 10-30 minutes to become ready"
      
      if [[ $attempt -ge $CLUSTER_READINESS_MAX_ATTEMPTS ]]; then
        echo "‚ùå TIMEOUT: Clusters are still not ready after $CLUSTER_READINESS_MAX_ATTEMPTS attempts ($((CLUSTER_READINESS_MAX_ATTEMPTS * CLUSTER_READINESS_SLEEP / 60)) minutes)"
        echo "   Unready clusters: ${unready_clusters[*]}"
        echo "   This may indicate a problem with cluster deployment"
        echo "   The precheck will continue but certificate extraction may fail"
        return 1
      else
        sleep $CLUSTER_READINESS_SLEEP
        ((attempt++))
      fi
    fi
  done
  
  return 1
}

# Function to check certificate distribution
check_certificate_distribution() {
  echo "Checking certificate distribution status..."
  
  if ! oc get configmap cluster-proxy-ca-bundle -n openshift-config >/dev/null 2>&1; then
    echo "‚ùå CA bundle ConfigMap not found on hub cluster"
    return 1
  fi
  
  bundle_content=$(oc get configmap cluster-proxy-ca-bundle -n openshift-config -o jsonpath="{.data['ca-bundle\.crt']}" 2>/dev/null || echo "")
  
  if [[ -z "$bundle_content" ]]; then
    echo "‚ùå CA bundle is empty"
    return 1
  fi
  
  bundle_size=$(echo "$bundle_content" | wc -c)
  echo "  Bundle size: $bundle_size bytes"
  
  if [[ $bundle_size -lt $MIN_BUNDLE_SIZE ]]; then
    echo "‚ùå CA bundle too small ($bundle_size < $MIN_BUNDLE_SIZE bytes)"
    return 1
  fi
  
  cert_count=$(echo "$bundle_content" | grep -c "BEGIN CERTIFICATE" || echo "0")
  echo "  Certificate count: $cert_count"
  
  if [[ $cert_count -lt $MIN_CERTIFICATES ]]; then
    echo "‚ùå Too few certificates ($cert_count < $MIN_CERTIFICATES)"
    return 1
  fi
  
  hub_certs=$(echo "$bundle_content" | grep -c "hub" || echo "0")
  ocp_primary_certs=$(echo "$bundle_content" | grep -c "ocp-primary" || echo "0")
  ocp_secondary_certs=$(echo "$bundle_content" | grep -c "ocp-secondary" || echo "0")
  
  echo "  Hub cluster certificates: $hub_certs"
  echo "  ocp-primary certificates: $ocp_primary_certs"
  echo "  ocp-secondary certificates: $ocp_secondary_certs"
  
  if [[ $hub_certs -lt 2 || $ocp_primary_certs -lt 2 || $ocp_secondary_certs -lt 2 ]]; then
    echo "‚ùå Missing certificates from one or more clusters"
    return 1
  fi
  
  echo "‚úÖ CA bundle is complete and properly distributed"
  return 0
}

# Function to trigger certificate extraction
trigger_certificate_extraction() {
  echo "Triggering certificate extraction..."
  
  oc delete job odf-ssl-certificate-extractor -n openshift-config --ignore-not-found=true
  sleep 5
  
  echo "Creating certificate extraction job..."
  oc apply -f - <<EOF
apiVersion: batch/v1
kind: Job
metadata:
  name: odf-ssl-certificate-extractor
  namespace: openshift-config
  labels:
    app.kubernetes.io/name: odf-ssl-certificate-management
    app.kubernetes.io/component: certificate-extraction
  annotations:
    argocd.argoproj.io/sync-wave: "1"
spec:
  template:
    spec:
      containers:
      - name: odf-ssl-extractor
        image: registry.redhat.io/openshift4/ose-cli:latest
        resources:
          requests:
            memory: "512Mi"
            cpu: "200m"
          limits:
            memory: "1Gi"
            cpu: "500m"
        command:
        - /bin/bash
        - -c
        - |
          set -euo pipefail
          
          echo "Starting ODF SSL certificate extraction and distribution..."
          echo "Following Red Hat ODF Disaster Recovery certificate management guidelines"
          
          # Configuration for retry logic
          MAX_RETRIES=5
          BASE_DELAY=30
          MAX_DELAY=300
          RETRY_COUNT=0
          
          # Function to implement exponential backoff
          exponential_backoff() {
            local delay=$((BASE_DELAY * (2 ** RETRY_COUNT)))
            if [[ $delay -gt $MAX_DELAY ]]; then
              delay=$MAX_DELAY
            fi
            echo "‚è≥ Waiting $delay seconds before retry (attempt $((RETRY_COUNT + 1))/$MAX_RETRIES)..."
            sleep $delay
            ((RETRY_COUNT++))
          }
          
          # Function to handle errors gracefully
          handle_error() {
            local error_msg="$1"
            echo "‚ùå Error: $error_msg"
            
            if [[ $RETRY_COUNT -lt $MAX_RETRIES ]]; then
              echo "üîÑ Retrying in a moment..."
              exponential_backoff
              return 0
            else
              echo "üí• Max retries exceeded. Job will exit but ArgoCD can retry the sync."
              echo "   This is a temporary failure - the job will be retried on next ArgoCD sync."
              exit 1
            fi
          }
          
          # Main execution with retry logic
          main_execution() {
            WORK_DIR="/tmp/odf-ssl-certs"
            mkdir -p "$WORK_DIR"
            cd "$WORK_DIR"
          
          extract_cluster_ca() {
            cluster_name="$1"
            output_file="$2"
            kubeconfig="${3:-}"
            
            echo "Extracting CA from cluster: $cluster_name"
            
            if [[ -n "$kubeconfig" && -f "$kubeconfig" ]]; then
              KUBECONFIG="$kubeconfig" oc get configmap -n openshift-config-managed trusted-ca-bundle -o jsonpath="{.data['ca-bundle\.crt']}" > "$output_file"
              echo "  CA extracted from $cluster_name using kubeconfig"
            else
              oc get configmap -n openshift-config-managed trusted-ca-bundle -o jsonpath="{.data['ca-bundle\.crt']}" > "$output_file"
              echo "  CA extracted from $cluster_name using current context"
            fi
            
            cert_size=$(wc -c < "$output_file" 2>/dev/null || echo "0")
            echo "  Certificate size: $cert_size bytes"
            
            if [[ $cert_size -lt 1000 ]]; then
              echo "  Warning: Certificate size seems too small"
              return 1
            fi
            
            return 0
          }
          
          extract_ingress_ca() {
            cluster_name="$1"
            output_file="$2"
            kubeconfig="${3:-}"
            
            echo "Extracting ingress CA from cluster: $cluster_name"
            
            if [[ -n "$kubeconfig" && -f "$kubeconfig" ]]; then
              KUBECONFIG="$kubeconfig" oc get configmap -n openshift-config-managed router-ca -o jsonpath="{.data['ca-bundle\.crt']}" > "$output_file" 2>/dev/null || echo "" > "$output_file"
              echo "  Ingress CA extracted from $cluster_name using kubeconfig"
            else
              oc get configmap -n openshift-config-managed router-ca -o jsonpath="{.data['ca-bundle\.crt']}" > "$output_file" 2>/dev/null || echo "" > "$output_file"
              echo "  Ingress CA extracted from $cluster_name using current context"
            fi
            
            cert_size=$(wc -c < "$output_file" 2>/dev/null || echo "0")
            echo "  Ingress CA certificate size: $cert_size bytes"
            
            return 0
          }
          
          create_combined_ca_bundle() {
            output_file="$1"
            shift
            ca_files=("$@")
            
            echo "Creating combined CA bundle..."
            > "$output_file"
            
            file_count=0
            for ca_file in "${ca_files[@]}"; do
              if [[ -f "$ca_file" && -s "$ca_file" ]]; then
                echo "# CA from $(basename "$ca_file" .crt)" >> "$output_file"
                
                cert_count=0
                in_cert=false
                while IFS= read -r line; do
                  if [[ "$line" == "-----BEGIN CERTIFICATE-----" ]]; then
                    in_cert=true
                    cert_count=$((cert_count + 1))
                    if [[ $cert_count -gt 5 ]]; then
                      break
                    fi
                  fi
                  if [[ $in_cert == true ]]; then
                    echo "$line" >> "$output_file"
                  fi
                  if [[ "$line" == "-----END CERTIFICATE-----" ]]; then
                    in_cert=false
                    echo "" >> "$output_file"
                  fi
                done < "$ca_file"
                
                file_count=$((file_count + 1))
              fi
            done
            
            if [[ $file_count -gt 0 ]]; then
              echo "Combined CA bundle created with $file_count CA sources (first 5 certs each)"
              return 0
            else
              echo "No valid CA files found to combine"
              return 1
            fi
          }
          
          echo "1. Extracting hub cluster CA..."
          hub_ca_extracted=false
          if extract_cluster_ca "hub" ""; then
            hub_ca_extracted=true
            echo "  ‚úÖ Hub CA extracted successfully"
          else
            echo "  ‚ùå Hub CA extraction failed - REQUIRED for DR setup"
          fi
          
          extract_ingress_ca "hub" ""
          
          echo "2. Discovering managed clusters..."
          managed_clusters=$(oc get managedclusters -o jsonpath='{.items[*].metadata.name}' | tr ' ' '\n' | grep -v local-cluster || echo "")
          echo "  Found managed clusters: $managed_clusters"
          
          echo "  Added hub CA to bundle"
          echo "  Added hub ingress CA to bundle"
          
          # Track required clusters
          REQUIRED_CLUSTERS=("hub" "ocp-primary" "ocp-secondary")
          EXTRACTED_CLUSTERS=()
          if [[ "$hub_ca_extracted" == "true" ]]; then
            EXTRACTED_CLUSTERS+=("hub")
          fi
          
          cluster_count=0
          for cluster in $managed_clusters; do
            if [[ "$cluster" == "ocp-primary" || "$cluster" == "ocp-secondary" ]]; then
              cluster_count=$((cluster_count + 1))
              echo "3.$cluster_count Extracting CA from $cluster..."
              
              kubeconfig_file="/tmp/odf-ssl-certs/${cluster}-kubeconfig.yaml"
              oc get secret "${cluster}-import" -n "${cluster}" -o jsonpath="{.data.kubeconfig}" | base64 -d > "$kubeconfig_file" 2>/dev/null || {
                echo "  ‚ùå Could not get kubeconfig for $cluster - REQUIRED for DR setup"
                continue
              }
              
              if extract_cluster_ca "$cluster" "$kubeconfig_file"; then
                EXTRACTED_CLUSTERS+=("$cluster")
                echo "  ‚úÖ CA extracted from $cluster"
              else
                echo "  ‚ùå CA extraction failed from $cluster - REQUIRED for DR setup"
              fi
              
              extract_ingress_ca "$cluster" "$kubeconfig_file"
            fi
          done
          
          # Validate that we have CA material from all required clusters
          echo "4. Validating CA extraction from required clusters..."
          MISSING_CLUSTERS=()
          for required_cluster in "${REQUIRED_CLUSTERS[@]}"; do
            if [[ " ${EXTRACTED_CLUSTERS[@]} " =~ " ${required_cluster} " ]]; then
              echo "  ‚úÖ CA extracted from $required_cluster"
            else
              echo "  ‚ùå CA NOT extracted from $required_cluster"
              MISSING_CLUSTERS+=("$required_cluster")
            fi
          done
          
          if [[ ${#MISSING_CLUSTERS[@]} -gt 0 ]]; then
            echo ""
            echo "‚ùå CRITICAL ERROR: CA material missing from required clusters:"
            for missing in "${MISSING_CLUSTERS[@]}"; do
              echo "   - $missing"
            done
            echo ""
            echo "The ODF SSL certificate extractor job requires CA material from ALL three clusters:"
            echo "   - hub (hub cluster)"
            echo "   - ocp-primary (primary managed cluster)"  
            echo "   - ocp-secondary (secondary managed cluster)"
            echo ""
            echo "Without CA material from all clusters, the DR setup will fail."
            echo "Please ensure all clusters are accessible and have proper kubeconfigs."
            echo ""
            echo "Job will exit with error code 1."
            exit 1
          fi
          
          echo "5. Creating combined CA bundle..."
          ca_files=$(ls -1 *.crt 2>/dev/null | wc -l)
          echo "  CA files to combine: $ca_files files"
          
          for file in *.crt; do
            if [[ -f "$file" ]]; then
              file_size=$(wc -c < "$file" 2>/dev/null || echo "0")
              echo "    - $file ($file_size bytes)"
            fi
          done
          
          create_combined_ca_bundle "combined-ca-bundle.crt" *.crt
          
          bundle_size=$(wc -c < combined-ca-bundle.crt)
          cert_count=$(grep -c "BEGIN CERTIFICATE" combined-ca-bundle.crt || echo "0")
          
          echo "Combined CA bundle created with $ca_files CA sources (first 5 certs each)"
          echo "  Combined CA bundle created successfully"
          echo "  Bundle size: $bundle_size bytes"
          echo "  Certificate count: $cert_count"
          
          if [[ $bundle_size -lt 20000 ]]; then
            echo "‚ùå Combined CA bundle too small ($bundle_size < 20000 bytes)"
            exit 1
          fi
          
          if [[ $cert_count -lt 15 ]]; then
            echo "‚ùå Too few certificates in combined CA bundle ($cert_count < 15)"
            exit 1
          fi
          
          echo "6. Updating hub cluster ConfigMap..."
          oc create configmap cluster-proxy-ca-bundle \
            --from-file=ca-bundle.crt=combined-ca-bundle.crt \
            -n openshift-config \
            --dry-run=client -o yaml | oc apply -f -
          
          echo "  Hub cluster ConfigMap updated"
          
          echo "7. Updating hub cluster proxy configuration..."
          oc patch proxy/cluster --type=merge --patch='{"spec":{"trustedCA":{"name":"cluster-proxy-ca-bundle"}}}' || {
            echo "  Warning: Could not update hub cluster proxy"
          }
          
          # Restart ramenddr-cluster-operator pods on managed clusters before updating configmap
          echo "7a. Restarting ramenddr-cluster-operator pods on managed clusters..."
          
          MANAGED_CLUSTERS=$(oc get managedclusters -o jsonpath='{.items[*].metadata.name}' 2>/dev/null || echo "")
          
          for cluster in $MANAGED_CLUSTERS; do
            if [[ "$cluster" == "local-cluster" ]]; then
              continue
            fi
            
            echo "  Processing cluster: $cluster"
            
            # Get kubeconfig for the cluster
            KUBECONFIG_FILE=""
            if oc get secret -n "$cluster" -o name | grep -E "(admin-kubeconfig|kubeconfig)" | head -1 | xargs -I {} oc get {} -n "$cluster" -o jsonpath='{.data.kubeconfig}' | base64 -d > "/tmp/${cluster}-kubeconfig.yaml" 2>/dev/null; then
              KUBECONFIG_FILE="/tmp/${cluster}-kubeconfig.yaml"
            fi
            
            if [[ -n "$KUBECONFIG_FILE" && -f "$KUBECONFIG_FILE" ]]; then
              # Find ramenddr-cluster-operator pods
              RAMEN_PODS=$(oc --kubeconfig="$KUBECONFIG_FILE" get pods -n openshift-dr-system -l app=ramenddr-cluster-operator -o jsonpath='{.items[*].metadata.name}' 2>/dev/null || echo "")
              
              if [[ -n "$RAMEN_PODS" ]]; then
                echo "    Found ramenddr-cluster-operator pods: $RAMEN_PODS"
                
                for pod in $RAMEN_PODS; do
                  echo "    Deleting pod $pod to trigger restart..."
                  oc --kubeconfig="$KUBECONFIG_FILE" delete pod "$pod" -n openshift-dr-system --ignore-not-found=true || {
                    echo "    Warning: Could not delete pod $pod"
                  }
                done
                
                # Wait for pods to be deleted
                echo "    Waiting for pods to be terminated..."
                for pod in $RAMEN_PODS; do
                  oc --kubeconfig="$KUBECONFIG_FILE" wait --for=delete pod/"$pod" -n openshift-dr-system --timeout=60s 2>/dev/null || true
                done
                
                # Wait for new pods to be running
                echo "    Waiting for new ramenddr-cluster-operator pods to be running..."
                MAX_WAIT_ATTEMPTS=30
                WAIT_INTERVAL=10
                attempt=0
                
                while [[ $attempt -lt $MAX_WAIT_ATTEMPTS ]]; do
                  attempt=$((attempt + 1))
                  
                  NEW_PODS=$(oc --kubeconfig="$KUBECONFIG_FILE" get pods -n openshift-dr-system -l app=ramenddr-cluster-operator -o jsonpath='{.items[*].metadata.name}' 2>/dev/null || echo "")
                  ALL_RUNNING=true
                  
                  if [[ -n "$NEW_PODS" ]]; then
                    for pod in $NEW_PODS; do
                      POD_STATUS=$(oc --kubeconfig="$KUBECONFIG_FILE" get pod "$pod" -n openshift-dr-system -o jsonpath='{.status.phase}' 2>/dev/null || echo "Unknown")
                      
                      if [[ "$POD_STATUS" != "Running" ]]; then
                        ALL_RUNNING=false
                        break
                      fi
                    done
                    
                    if [[ "$ALL_RUNNING" == "true" ]]; then
                      echo "    ‚úÖ All ramenddr-cluster-operator pods are running on $cluster: $NEW_PODS"
                      break
                    else
                      echo "    ‚è≥ Waiting for pods to be running (attempt $attempt/$MAX_WAIT_ATTEMPTS)"
                    fi
                  else
                    echo "    ‚è≥ Waiting for pods to appear (attempt $attempt/$MAX_WAIT_ATTEMPTS)"
                  fi
                  
                  if [[ $attempt -lt $MAX_WAIT_ATTEMPTS ]]; then
                    sleep $WAIT_INTERVAL
                  fi
                done
                
                if [[ $attempt -ge $MAX_WAIT_ATTEMPTS ]]; then
                  echo "    ‚ö†Ô∏è  Warning: ramenddr-cluster-operator pods did not become ready within expected time on $cluster"
                  echo "     The pods may still be starting - configuration changes will be applied when ready"
                fi
              else
                echo "    ‚ö†Ô∏è  Warning: ramenddr-cluster-operator pods not found on $cluster - they may not be deployed yet"
                echo "     Configuration changes will be applied when the pods start"
              fi
            else
              echo "    ‚ùå Could not get kubeconfig for $cluster - skipping pod restart"
            fi
          done
          
          echo "  ‚úÖ Completed ramenddr-cluster-operator pod restarts on managed clusters"
          
          # Update ramen-hub-operator-config with base64-encoded CA bundle
          echo "7b. Updating ramen-hub-operator-config in openshift-operators namespace..."
          
          # Base64 encode the combined CA bundle
          CA_BUNDLE_BASE64=$(base64 -w 0 < combined-ca-bundle.crt 2>/dev/null || base64 < combined-ca-bundle.crt | tr -d '\n')
          
          # Check if ramen-hub-operator-config exists
          if oc get configmap ramen-hub-operator-config -n openshift-operators &>/dev/null; then
            echo "  ConfigMap exists, updating ramen_manager_config.yaml with caCertificates in s3StoreProfiles..."
            
            # Get existing ramen_manager_config.yaml content
            EXISTING_YAML=$(oc get configmap ramen-hub-operator-config -n openshift-operators -o jsonpath='{.data.ramen_manager_config\.yaml}' 2>/dev/null || echo "")
            
            # Create updated YAML with caCertificates in each s3StoreProfiles item
            if [[ -n "$EXISTING_YAML" ]]; then
              # Create a temporary YAML file with the update
              echo "$EXISTING_YAML" > existing-ramen-config.yaml
              
              # Use yq to update caCertificates in each s3StoreProfiles item
              if command -v yq &>/dev/null; then
                # Update caCertificates for each item in s3StoreProfiles array
                yq eval ".s3StoreProfiles[]?.caCertificates = \"$CA_BUNDLE_BASE64\"" -i existing-ramen-config.yaml 2>/dev/null || {
                  echo "  Warning: Could not update s3StoreProfiles with yq, trying alternative approach..."
                  # Fallback: manually add caCertificates to each profile
                  python3 -c "
import yaml
import sys

with open('existing-ramen-config.yaml', 'r') as f:
    config = yaml.safe_load(f) or {}

if 's3StoreProfiles' not in config:
    config['s3StoreProfiles'] = []

for profile in config.get('s3StoreProfiles', []):
    profile['caCertificates'] = '$CA_BUNDLE_BASE64'

with open('existing-ramen-config.yaml', 'w') as f:
    yaml.dump(config, f, default_flow_style=False, sort_keys=False)
" 2>/dev/null || {
                    echo "  Warning: Python/yaml not available, using sed fallback..."
                    # Very basic sed fallback - add caCertificates after each profile name
                    sed -i "/^  - name:/a\    caCertificates: \"$CA_BUNDLE_BASE64\"" existing-ramen-config.yaml 2>/dev/null || true
                  }
                }
              else
                # Fallback: use Python if available
                if command -v python3 &>/dev/null; then
                  python3 -c "
import yaml
import sys

with open('existing-ramen-config.yaml', 'r') as f:
    config = yaml.safe_load(f) or {}

if 's3StoreProfiles' not in config:
    config['s3StoreProfiles'] = []

for profile in config.get('s3StoreProfiles', []):
    profile['caCertificates'] = '$CA_BUNDLE_BASE64'

with open('existing-ramen-config.yaml', 'w') as f:
    yaml.dump(config, f, default_flow_style=False, sort_keys=False)
" 2>/dev/null || {
                    echo "  Warning: Python yaml module not available, using sed fallback..."
                    # Very basic sed fallback
                    sed -i "/^  - name:/a\    caCertificates: \"$CA_BUNDLE_BASE64\"" existing-ramen-config.yaml 2>/dev/null || true
                  }
                else
                  echo "  Error: yq or python3 not available - cannot update s3StoreProfiles"
                  echo "  Manual intervention required"
                fi
              fi
              
              UPDATED_YAML=$(cat existing-ramen-config.yaml)
            else
              # No existing YAML, create new one with s3StoreProfiles containing caCertificates
              UPDATED_YAML="s3StoreProfiles:
  - name: default
    caCertificates: \"$CA_BUNDLE_BASE64\""
            fi
            
            # Create patch file for ConfigMap update
            echo "data:" > ramen-patch.yaml
            echo "  ramen_manager_config.yaml: |" >> ramen-patch.yaml
            echo "$UPDATED_YAML" | sed 's/^/    /' >> ramen-patch.yaml
            
            # Patch the ConfigMap with updated YAML
            if oc patch configmap ramen-hub-operator-config -n openshift-operators \
              --type=merge \
              --patch-file=ramen-patch.yaml 2>&1; then
              
              # Verify the patch was successful
              sleep 2
              VERIFIED_YAML=$(oc get configmap ramen-hub-operator-config -n openshift-operators -o jsonpath='{.data.ramen_manager_config\.yaml}' 2>/dev/null || echo "")
              
              if echo "$VERIFIED_YAML" | grep -q "s3StoreProfiles" && echo "$VERIFIED_YAML" | grep -q "caCertificates" && echo "$VERIFIED_YAML" | grep -q "$CA_BUNDLE_BASE64"; then
                echo "  ‚úÖ ramen-hub-operator-config updated and verified successfully"
                echo "     caCertificates added to all s3StoreProfiles items"
              else
                echo "  ‚ö†Ô∏è  Warning: ramen-hub-operator-config patched but verification failed"
                echo "     The caCertificates field may not have been set correctly in s3StoreProfiles"
                echo "     Current YAML content (first 10 lines):"
                echo "$VERIFIED_YAML" | head -n 10
              fi
            else
              echo "  ‚ùå Error: Could not patch ramen-hub-operator-config"
              echo "     Attempting alternative approach using oc apply..."
              
              # Alternative: Use oc apply with the patch file
              if oc apply -f ramen-patch.yaml 2>&1; then
                sleep 2
                VERIFIED_YAML=$(oc get configmap ramen-hub-operator-config -n openshift-operators -o jsonpath='{.data.ramen_manager_config\.yaml}' 2>/dev/null || echo "")
                
                if echo "$VERIFIED_YAML" | grep -q "s3StoreProfiles" && echo "$VERIFIED_YAML" | grep -q "caCertificates" && echo "$VERIFIED_YAML" | grep -q "$CA_BUNDLE_BASE64"; then
                  echo "  ‚úÖ ramen-hub-operator-config updated using alternative approach"
                else
                  echo "  ‚ö†Ô∏è  Warning: Alternative approach applied but verification failed"
                fi
              else
                echo "  ‚ùå Alternative approach also failed"
                echo "     Manual intervention may be required to set caCertificates in s3StoreProfiles"
              fi
            fi
            
            rm -f existing-ramen-config.yaml ramen-patch.yaml
            
          else
            echo "  ConfigMap does not exist, creating with ramen_manager_config.yaml containing s3StoreProfiles with caCertificates..."
            oc create configmap ramen-hub-operator-config -n openshift-operators \
              --from-literal=ramen_manager_config.yaml="s3StoreProfiles:
  - name: default
    caCertificates: \"$CA_BUNDLE_BASE64\"" || {
              echo "  Warning: Could not create ramen-hub-operator-config"
            }
          fi
          
          echo "  ramen-hub-operator-config updated successfully with base64-encoded CA bundle in s3StoreProfiles"
          echo "  This enables SSL access for discovered applications in ODF Disaster Recovery"
          
          # Restart Velero pods on managed clusters to pick up new CA certificates
          echo "7c. Restarting Velero pods on managed clusters..."
          
          MANAGED_CLUSTERS=$(oc get managedclusters -o jsonpath='{.items[*].metadata.name}' 2>/dev/null || echo "")
          
          for cluster in $MANAGED_CLUSTERS; do
            if [[ "$cluster" == "local-cluster" ]]; then
              continue
            fi
            
            echo "  Processing cluster: $cluster"
            
            # Get kubeconfig for the cluster
            KUBECONFIG_FILE="/tmp/${cluster}-kubeconfig.yaml"
            if [[ ! -f "$KUBECONFIG_FILE" ]]; then
              # Fetch kubeconfig if not already available
              if oc get secret -n "$cluster" -o name | grep -E "(admin-kubeconfig|kubeconfig)" | head -1 | xargs -I {} oc get {} -n "$cluster" -o jsonpath='{.data.kubeconfig}' | base64 -d > "$KUBECONFIG_FILE" 2>/dev/null; then
                echo "    Fetched kubeconfig for $cluster"
              else
                echo "    ‚ùå Could not get kubeconfig for $cluster - skipping Velero pod restart"
                continue
              fi
            fi
            
            # Find Velero pods in openshift-adp namespace
            VELERO_PODS=$(oc --kubeconfig="$KUBECONFIG_FILE" get pods -n openshift-adp -l component=velero -o jsonpath='{.items[*].metadata.name}' 2>/dev/null || echo "")
            
            if [[ -n "$VELERO_PODS" ]]; then
                echo "    Found Velero pods: $VELERO_PODS"
                
                for pod in $VELERO_PODS; do
                  echo "    Deleting pod $pod to trigger restart..."
                  oc --kubeconfig="$KUBECONFIG_FILE" delete pod "$pod" -n openshift-adp --ignore-not-found=true || {
                    echo "    Warning: Could not delete pod $pod"
                  }
                done
                
                # Wait for pods to be deleted
                echo "    Waiting for pods to be terminated..."
                for pod in $VELERO_PODS; do
                  oc --kubeconfig="$KUBECONFIG_FILE" wait --for=delete pod/"$pod" -n openshift-adp --timeout=60s 2>/dev/null || true
                done
                
                # Wait for new pods to be running
                echo "    Waiting for new Velero pods to be running..."
                MAX_WAIT_ATTEMPTS=30
                WAIT_INTERVAL=10
                attempt=0
                
                while [[ $attempt -lt $MAX_WAIT_ATTEMPTS ]]; do
                  attempt=$((attempt + 1))
                  
                  NEW_PODS=$(oc --kubeconfig="$KUBECONFIG_FILE" get pods -n openshift-adp -l component=velero -o jsonpath='{.items[*].metadata.name}' 2>/dev/null || echo "")
                  ALL_RUNNING=true
                  
                  if [[ -n "$NEW_PODS" ]]; then
                    for pod in $NEW_PODS; do
                      POD_STATUS=$(oc --kubeconfig="$KUBECONFIG_FILE" get pod "$pod" -n openshift-adp -o jsonpath='{.status.phase}' 2>/dev/null || echo "Unknown")
                      
                      if [[ "$POD_STATUS" != "Running" ]]; then
                        ALL_RUNNING=false
                        break
                      fi
                    done
                    
                    if [[ "$ALL_RUNNING" == "true" ]]; then
                      echo "    ‚úÖ All Velero pods are running on $cluster: $NEW_PODS"
                      break
                    else
                      echo "    ‚è≥ Waiting for pods to be running (attempt $attempt/$MAX_WAIT_ATTEMPTS)"
                    fi
                  else
                    echo "    ‚è≥ Waiting for pods to appear (attempt $attempt/$MAX_WAIT_ATTEMPTS)"
                  fi
                  
                  if [[ $attempt -lt $MAX_WAIT_ATTEMPTS ]]; then
                    sleep $WAIT_INTERVAL
                  fi
                done
                
                if [[ $attempt -ge $MAX_WAIT_ATTEMPTS ]]; then
                  echo "    ‚ö†Ô∏è  Warning: Velero pods did not become ready within expected time on $cluster"
                  echo "     The pods may still be starting - new CA certificates will be applied when ready"
                fi
              else
                echo "    ‚ö†Ô∏è  Warning: Velero pods not found on $cluster - they may not be deployed yet"
                echo "     New CA certificates will be applied when the pods start"
              fi
          done
          
          echo "  ‚úÖ Completed Velero pod restarts on managed clusters"
          
          echo "8. Distributing certificate data to managed clusters..."
          DISTRIBUTION_ATTEMPTS=3
          DISTRIBUTION_SLEEP=10
          
          for cluster in $MANAGED_CLUSTERS; do
            if [[ "$cluster" == "local-cluster" ]]; then
              continue
            fi
            
            echo "  Distributing to $cluster..."
            
            KUBECONFIG_FILE=""
            if oc get secret -n "$cluster" -o name | grep -E "(admin-kubeconfig|kubeconfig)" | head -1 | xargs -I {} oc get {} -n "$cluster" -o jsonpath='{.data.kubeconfig}' | base64 -d > "$WORK_DIR/${cluster}-kubeconfig.yaml" 2>/dev/null; then
              KUBECONFIG_FILE="$WORK_DIR/${cluster}-kubeconfig.yaml"
            fi
            
            if [[ -n "$KUBECONFIG_FILE" && -f "$KUBECONFIG_FILE" ]]; then
              distribution_success=false
              for dist_attempt in $(seq 1 $DISTRIBUTION_ATTEMPTS); do
                echo "    Distribution attempt $dist_attempt/$DISTRIBUTION_ATTEMPTS for $cluster..."
                
                if oc --kubeconfig="$KUBECONFIG_FILE" create configmap cluster-proxy-ca-bundle \
                  --from-file=ca-bundle.crt="$WORK_DIR/combined-ca-bundle.crt" \
                  -n openshift-config \
                  --dry-run=client -o yaml | oc --kubeconfig="$KUBECONFIG_FILE" apply -f -; then
                  
                  if oc --kubeconfig="$KUBECONFIG_FILE" patch proxy/cluster --type=merge --patch='{"spec":{"trustedCA":{"name":"cluster-proxy-ca-bundle"}}}'; then
                    echo "    ‚úÖ Certificate data distributed to $cluster (attempt $dist_attempt)"
                    distribution_success=true
                    break
                  else
                    echo "    ‚ö†Ô∏è  ConfigMap created but proxy update failed for $cluster (attempt $dist_attempt)"
                  fi
                else
                    echo "    ‚ö†Ô∏è  ConfigMap creation failed for $cluster (attempt $dist_attempt)"
                fi
                
                if [[ $dist_attempt -lt $DISTRIBUTION_ATTEMPTS ]]; then
                  echo "    ‚è≥ Waiting $DISTRIBUTION_SLEEP seconds before retry..."
                  sleep $DISTRIBUTION_SLEEP
                fi
              done
              
              if [[ "$distribution_success" != "true" ]]; then
                echo "    ‚ùå Failed to distribute certificate data to $cluster after $DISTRIBUTION_ATTEMPTS attempts"
                echo "    This may cause DR prerequisites check to fail"
              fi
            else
              echo "    ‚ùå Could not get kubeconfig for $cluster - skipping distribution"
            fi
          done
          
          echo "9. Verifying certificate distribution to managed clusters..."
          verification_failed=false
          REQUIRED_VERIFICATION_CLUSTERS=("ocp-primary" "ocp-secondary")
          VERIFIED_CLUSTERS=()
          
          for cluster in $MANAGED_CLUSTERS; do
            if [[ "$cluster" == "local-cluster" ]]; then
              continue
            fi
            
            echo "  Verifying distribution to $cluster..."
            KUBECONFIG_FILE="$WORK_DIR/${cluster}-kubeconfig.yaml"
            
            if [[ -f "$KUBECONFIG_FILE" ]]; then
              configmap_exists=$(oc --kubeconfig="$KUBECONFIG_FILE" get configmap cluster-proxy-ca-bundle -n openshift-config &>/dev/null && echo "true" || echo "false")
              configmap_size=$(oc --kubeconfig="$KUBECONFIG_FILE" get configmap cluster-proxy-ca-bundle -n openshift-config -o jsonpath='{.data.ca-bundle\.crt}' 2>/dev/null | wc -c || echo "0")
              proxy_configured=$(oc --kubeconfig="$KUBECONFIG_FILE" get proxy cluster -o jsonpath='{.spec.trustedCA.name}' 2>/dev/null || echo "")
              
              if [[ "$configmap_exists" == "true" && $configmap_size -gt 100 && "$proxy_configured" == "cluster-proxy-ca-bundle" ]]; then
                echo "    ‚úÖ $cluster: ConfigMap exists (${configmap_size} bytes), proxy configured"
                VERIFIED_CLUSTERS+=("$cluster")
              else
                echo "    ‚ùå $cluster: ConfigMap verification failed"
                echo "      ConfigMap exists: $configmap_exists"
                echo "      ConfigMap size: $configmap_size bytes"
                echo "      Proxy configured: $proxy_configured"
                verification_failed=true
              fi
            else
              echo "    ‚ùå $cluster: No kubeconfig available for verification"
              verification_failed=true
            fi
          done
          
          # Check if all required clusters are verified
          echo "10. Validating verification results..."
          MISSING_VERIFICATION_CLUSTERS=()
          for required_cluster in "${REQUIRED_VERIFICATION_CLUSTERS[@]}"; do
            if [[ " ${VERIFIED_CLUSTERS[@]} " =~ " ${required_cluster} " ]]; then
              echo "  ‚úÖ $required_cluster: Certificate distribution verified"
            else
              echo "  ‚ùå $required_cluster: Certificate distribution NOT verified"
              MISSING_VERIFICATION_CLUSTERS+=("$required_cluster")
            fi
          done
          
          if [[ ${#MISSING_VERIFICATION_CLUSTERS[@]} -gt 0 ]]; then
            echo ""
            echo "‚ùå CRITICAL ERROR: Certificate distribution verification failed for required clusters:"
            for missing in "${MISSING_VERIFICATION_CLUSTERS[@]}"; do
              echo "   - $missing"
            done
            echo ""
            echo "The ODF SSL certificate extractor job requires successful certificate distribution"
            echo "to ALL managed clusters (ocp-primary and ocp-secondary)."
            echo ""
            echo "Without proper certificate distribution, the DR setup will fail."
            echo "Please check cluster connectivity and kubeconfig availability."
            echo ""
            echo "Job will exit with error code 1."
            exit 1
          fi
          
          if [[ "$verification_failed" == "true" ]]; then
            echo ""
            echo "‚ö†Ô∏è  Certificate distribution verification failed for some clusters"
            echo "   This may cause DR prerequisites check to fail"
            echo "   Manual intervention may be required"
            echo ""
            echo "Job will exit with error code 1."
            exit 1
          else
            echo ""
            echo "‚úÖ All managed clusters verified successfully"
          fi
          
          echo ""
          echo "‚úÖ ODF SSL certificate management completed successfully!"
          echo "   - Hub cluster CA bundle: Updated (includes trusted CA + ingress CA)"
          echo "   - Hub cluster proxy: Configured"
          echo "   - Managed clusters: ramenddr-cluster-operator pods restarted"
          echo "   - ramen-hub-operator-config: Updated with base64-encoded CA bundle in s3StoreProfiles (hub cluster)"
          echo "   - Managed clusters: Velero pods restarted (openshift-adp namespace)"
          echo "   - Managed clusters: Certificate data distributed (includes ingress CAs)"
          echo ""
          echo "This follows Red Hat ODF Disaster Recovery certificate management guidelines"
          echo "for secure SSL access across clusters in the regional DR setup."
          echo "The ramen-hub-operator-config update enables SSL access for discovered applications"
          echo "as described in the Red Hat ODF Disaster Recovery documentation."
          }
          
          # Execute main function with retry logic
          while true; do
            if main_execution; then
              echo "üéâ Certificate extraction completed successfully!"
              exit 0
            else
              if [[ $RETRY_COUNT -lt $MAX_RETRIES ]]; then
                echo "üîÑ Main execution failed, retrying..."
                exponential_backoff
                continue
              else
                echo "üí• Max retries exceeded. Job will exit but ArgoCD can retry the sync."
                echo "   This is a temporary failure - the job will be retried on next ArgoCD sync."
                exit 1
              fi
            fi
          done
EOF
  
  echo "Certificate extraction job created"
  
  echo "Waiting for certificate extraction to complete..."
  attempt=0
  while [[ $attempt -lt $MAX_ATTEMPTS ]]; do
    attempt=$((attempt + 1))
    echo "  Attempt $attempt/$MAX_ATTEMPTS"
    
    if oc wait --for=condition=complete job/odf-ssl-certificate-extractor -n openshift-config --timeout=60s 2>/dev/null; then
      echo "  ‚úÖ Certificate extraction completed successfully"
      return 0
    else
      echo "  ‚è≥ Certificate extraction still running, waiting..."
      sleep $SLEEP_INTERVAL
    fi
  done
  
  echo "  ‚ùå Certificate extraction did not complete within expected time"
  return 1
}

# Main execution with retry logic
main_execution() {
  echo "üîç Starting certificate distribution check with retry logic..."
  
  # First, wait for required clusters to be ready
  echo "‚è≥ Waiting for required clusters to be available and joined before proceeding..."
  if wait_for_cluster_readiness; then
    echo "‚úÖ All required clusters are ready - proceeding with certificate checks"
  else
    echo "‚ö†Ô∏è  Some clusters are not ready yet, but continuing anyway..."
    echo "   The certificate extraction will be attempted when clusters become ready"
  fi
  
  attempt=1
  while [[ $attempt -le $MAX_ATTEMPTS ]]; do
    echo "=== Certificate Distribution Attempt $attempt/$MAX_ATTEMPTS ==="
    
    if check_certificate_distribution; then
      echo "‚úÖ Certificate distribution is complete and verified"
      echo "   All clusters have proper CA bundles"
      echo "üéØ ODF SSL certificate precheck completed successfully"
      echo "   Ready for DR prerequisites check"
      exit 0
    else
      echo "‚ùå Certificate distribution is incomplete or missing"
      
      echo "üßπ Cleaning up placeholder ConfigMaps..."
      cleanup_placeholder_configmaps
      
      echo "   Triggering certificate extraction (attempt $attempt/$MAX_ATTEMPTS)..."
      
      if trigger_certificate_extraction; then
        echo "‚úÖ Certificate extraction completed successfully"
        echo "   Re-verifying distribution..."
        
        sleep 10
        
        if check_certificate_distribution; then
          echo "‚úÖ Certificate distribution verified after extraction"
          echo "üéØ ODF SSL certificate precheck completed successfully"
          echo "   Ready for DR prerequisites check"
          exit 0
        else
          echo "‚ö†Ô∏è  Certificate extraction completed but distribution still incomplete"
          echo "   Will retry in $SLEEP_INTERVAL seconds..."
        fi
      else
        echo "‚ùå Certificate extraction failed (attempt $attempt/$MAX_ATTEMPTS)"
        echo "   Will retry in $SLEEP_INTERVAL seconds..."
      fi
    fi
    
    if [[ $attempt -lt $MAX_ATTEMPTS ]]; then
      echo "‚è≥ Waiting $SLEEP_INTERVAL seconds before next attempt..."
      sleep $SLEEP_INTERVAL
    fi
    
    ((attempt++))
  done
  
  echo "‚ùå Certificate distribution failed after $MAX_ATTEMPTS attempts"
  echo "   This may affect DR prerequisites check"
  echo "   Manual intervention may be required"
  exit 1
}

# Call main execution
main_execution
