apiVersion: batch/v1
kind: Job
metadata:
  name: argocd-health-monitor
  namespace: open-cluster-management
  labels:
    app.kubernetes.io/name: argocd-health-monitor
    app.kubernetes.io/component: health-check
  annotations:
    argocd.argoproj.io/sync-wave: "0"
spec:
  backoffLimit: 3
  template:
    spec:
      restartPolicy: OnFailure
      containers:
      - name: argocd-health-monitor
        image: registry.redhat.io/openshift4/ose-cli:latest
        command:
        - /bin/bash
        - -c
        - |
          set -euo pipefail
          
          echo "Starting ArgoCD health monitoring and remediation..."
          
          # Configuration
          MAX_ATTEMPTS=5
          SLEEP_INTERVAL=30
          ARGOCD_NAMESPACE="openshift-gitops"
          HEALTH_CHECK_TIMEOUT=60
          
              # Function to check if a cluster is wedged
              check_cluster_wedged() {
                local cluster="$1"
                local kubeconfig="$2"
                
                echo "Checking if $cluster is wedged..."
                
                # Check if we can connect to the cluster
                if ! oc --kubeconfig="$kubeconfig" get nodes --request-timeout=10s &>/dev/null; then
                  echo "‚ùå Cannot connect to $cluster - cluster appears wedged"
                  return 0
                fi
                
                # Determine the cluster-specific ArgoCD instance name and namespace
                local cluster_argocd_namespace=""
                local cluster_argocd_instance=""
                case "$cluster" in
                  "ocp-primary")
                    cluster_argocd_namespace="ramendr-starter-kit-resilient-1"
                    cluster_argocd_instance="resilient-1-gitops-server"
                    ;;
                  "ocp-secondary")
                    cluster_argocd_namespace="ramendr-starter-kit-resilient-2"
                    cluster_argocd_instance="resilient-2-gitops-server"
                    ;;
                  "local-cluster")
                    cluster_argocd_namespace="openshift-gitops"
                    cluster_argocd_instance="openshift-gitops"
                    ;;
                  *)
                    echo "‚ùå Unknown cluster $cluster - cannot determine ArgoCD instance"
                    return 0
                    ;;
                esac
                
                echo "Looking for cluster-specific ArgoCD instance: $cluster_argocd_instance in namespace: $cluster_argocd_namespace"
                
                # Check if the cluster-specific ArgoCD namespace exists
                if ! oc --kubeconfig="$kubeconfig" get namespace "$cluster_argocd_namespace" &>/dev/null; then
                  echo "‚ö†Ô∏è  Cluster-specific ArgoCD namespace $cluster_argocd_namespace not found on $cluster"
                  
                  # Check if openshift-gitops namespace exists and is wedged
                  if oc --kubeconfig="$kubeconfig" get namespace "$ARGOCD_NAMESPACE" &>/dev/null; then
                    echo "üîç Checking if openshift-gitops instance is wedged on $cluster..."
                    local openshift_gitops_pods=$(oc --kubeconfig="$kubeconfig" get pods -n "$ARGOCD_NAMESPACE" -l app.kubernetes.io/name=openshift-gitops-server --field-selector=status.phase=Running --no-headers 2>/dev/null | wc -l)
                    echo "Found $openshift_gitops_pods ArgoCD server pods in $ARGOCD_NAMESPACE namespace on $cluster"
                    
                    if [[ $openshift_gitops_pods -gt 0 ]]; then
                      echo "‚ùå openshift-gitops instance is running but cluster-specific ArgoCD is missing - cluster appears wedged"
                      return 0
                    fi
                  fi
                  
                  echo "‚úÖ $cluster appears healthy (no ArgoCD instances installed yet)"
                  return 1
                fi
                
                # Check if the cluster-specific ArgoCD instance exists and is running
                local cluster_argocd_pods=$(oc --kubeconfig="$kubeconfig" get pods -n "$cluster_argocd_namespace" -l app.kubernetes.io/name=openshift-gitops-server --field-selector=status.phase=Running --no-headers 2>/dev/null | wc -l)
                echo "Found $cluster_argocd_pods ArgoCD server pods in $cluster_argocd_namespace namespace on $cluster"
                
                if [[ $cluster_argocd_pods -eq 0 ]]; then
                  echo "‚ö†Ô∏è  No ArgoCD server pods found in $cluster_argocd_namespace namespace on $cluster"
                  
                  # Check if openshift-gitops instance is wedged
                  if oc --kubeconfig="$kubeconfig" get namespace "$ARGOCD_NAMESPACE" &>/dev/null; then
                    echo "üîç Checking if openshift-gitops instance is wedged on $cluster..."
                    local openshift_gitops_pods=$(oc --kubeconfig="$kubeconfig" get pods -n "$ARGOCD_NAMESPACE" -l app.kubernetes.io/name=openshift-gitops-server --field-selector=status.phase=Running --no-headers 2>/dev/null | wc -l)
                    echo "Found $openshift_gitops_pods ArgoCD server pods in $ARGOCD_NAMESPACE namespace on $cluster"
                    
                    if [[ $openshift_gitops_pods -gt 0 ]]; then
                      echo "‚ùå openshift-gitops instance is running but cluster-specific ArgoCD is missing - cluster appears wedged"
                      return 0
                    fi
                  fi
                  
                  echo "‚úÖ $cluster appears healthy (no ArgoCD instances running yet)"
                  return 1
                elif [[ $cluster_argocd_pods -eq 1 ]]; then
                  echo "‚ùå Only 1 ArgoCD server pod found in $cluster_argocd_namespace namespace on $cluster (expected 2) - cluster appears wedged"
                  return 0
                elif [[ $cluster_argocd_pods -eq 2 ]]; then
                  echo "‚úÖ Found 2 ArgoCD server pods in $cluster_argocd_namespace namespace on $cluster - cluster appears healthy"
                  return 1
                else
                  echo "‚ö†Ô∏è  Found $cluster_argocd_pods ArgoCD server pods in $cluster_argocd_namespace namespace on $cluster (expected 2) - cluster may be wedged"
                  return 0
                fi
              }
          
          # Function to remediate a wedged cluster with maximum violence
          remediate_wedged_cluster() {
            local cluster="$1"
            local kubeconfig="$2"
            
            echo "üîß Remediating wedged cluster: $cluster with MAXIMUM VIOLENCE"
            
            # MAXIMUM VIOLENCE: Delete everything in the openshift-gitops namespace
            echo "  üí• MAXIMUM VIOLENCE: Deleting ALL resources in $ARGOCD_NAMESPACE namespace..."
            
            # Delete all deployments with maximum force
            echo "  üí• Force deleting all deployments..."
            oc --kubeconfig="$kubeconfig" delete deployment --all -n "$ARGOCD_NAMESPACE" --grace-period=0 --force &>/dev/null || true
            
            # Delete all statefulsets with maximum force
            echo "  üí• Force deleting all statefulsets..."
            oc --kubeconfig="$kubeconfig" delete statefulset --all -n "$ARGOCD_NAMESPACE" --grace-period=0 --force &>/dev/null || true
            
            # Delete all daemonsets with maximum force
            echo "  üí• Force deleting all daemonsets..."
            oc --kubeconfig="$kubeconfig" delete daemonset --all -n "$ARGOCD_NAMESPACE" --grace-period=0 --force &>/dev/null || true
            
            # Delete all pods with maximum force
            echo "  üí• Force deleting all pods..."
            oc --kubeconfig="$kubeconfig" delete pods --all -n "$ARGOCD_NAMESPACE" --grace-period=0 --force &>/dev/null || true
            
            # Delete all services with maximum force
            echo "  üí• Force deleting all services..."
            oc --kubeconfig="$kubeconfig" delete service --all -n "$ARGOCD_NAMESPACE" --grace-period=0 --force &>/dev/null || true
            
            # Delete all configmaps with maximum force
            echo "  üí• Force deleting all configmaps..."
            oc --kubeconfig="$kubeconfig" delete configmap --all -n "$ARGOCD_NAMESPACE" --grace-period=0 --force &>/dev/null || true
            
            # Delete all secrets with maximum force
            echo "  üí• Force deleting all secrets..."
            oc --kubeconfig="$kubeconfig" delete secret --all -n "$ARGOCD_NAMESPACE" --grace-period=0 --force &>/dev/null || true
            
            # Delete all persistent volume claims with maximum force
            echo "  üí• Force deleting all PVCs..."
            oc --kubeconfig="$kubeconfig" delete pvc --all -n "$ARGOCD_NAMESPACE" --grace-period=0 --force &>/dev/null || true
            
            # Wait for everything to be deleted
            echo "  ‚è≥ Waiting for all resources to be deleted..."
            local attempt=1
            while [[ $attempt -le 60 ]]; do
              local remaining_resources=$(oc --kubeconfig="$kubeconfig" get all -n "$ARGOCD_NAMESPACE" --no-headers 2>/dev/null | wc -l)
              if [[ $remaining_resources -eq 0 ]]; then
                echo "  ‚úÖ All resources deleted from $ARGOCD_NAMESPACE namespace"
                break
              fi
              echo "  Waiting for resources to be deleted... (attempt $attempt/60) - $remaining_resources resources remaining"
              sleep 5
              ((attempt++))
            done
            
            # MAXIMUM VIOLENCE: Delete and recreate the namespace
            echo "  üí• MAXIMUM VIOLENCE: Deleting and recreating $ARGOCD_NAMESPACE namespace..."
            oc --kubeconfig="$kubeconfig" delete namespace "$ARGOCD_NAMESPACE" --grace-period=0 --force &>/dev/null || true
            
            # Wait for namespace to be deleted
            echo "  ‚è≥ Waiting for namespace to be deleted..."
            local attempt=1
            while [[ $attempt -le 30 ]]; do
              if ! oc --kubeconfig="$kubeconfig" get namespace "$ARGOCD_NAMESPACE" &>/dev/null; then
                echo "  ‚úÖ Namespace $ARGOCD_NAMESPACE deleted"
                break
              fi
              echo "  Waiting for namespace to be deleted... (attempt $attempt/30)"
              sleep 5
              ((attempt++))
            done
            
            # Recreate the namespace
            echo "  üîÑ Recreating $ARGOCD_NAMESPACE namespace..."
            oc --kubeconfig="$kubeconfig" create namespace "$ARGOCD_NAMESPACE" &>/dev/null || true
            
            # Wait for namespace to be ready
            echo "  ‚è≥ Waiting for namespace to be ready..."
            local attempt=1
            while [[ $attempt -le 30 ]]; do
              if oc --kubeconfig="$kubeconfig" get namespace "$ARGOCD_NAMESPACE" &>/dev/null; then
                echo "  ‚úÖ Namespace $ARGOCD_NAMESPACE recreated"
                break
              fi
              echo "  Waiting for namespace to be ready... (attempt $attempt/30)"
              sleep 5
              ((attempt++))
            done
            
            echo "  üí• MAXIMUM VIOLENCE remediation completed for $cluster"
            echo "  ‚ö†Ô∏è  Note: The openshift-gitops-operator will need to be reinstalled to restore functionality"
          }
          
              # Function to download kubeconfig for a cluster (using same logic as download-kubeconfigs.sh)
              download_kubeconfig() {
                local cluster="$1"
                local kubeconfig_path="/tmp/${cluster}-kubeconfig.yaml"
                
                echo "Downloading kubeconfig for $cluster..."
                
                # Check if cluster is available (same as download-kubeconfigs.sh)
                local cluster_status=$(oc get managedcluster "$cluster" -o jsonpath='{.status.conditions[?(@.type=="ManagedClusterConditionAvailable")].status}' 2>/dev/null || echo "Unknown")
                if [[ "$cluster_status" != "True" ]]; then
                  echo "Cluster $cluster is not available (status: $cluster_status), skipping..."
                  return 1
                fi
                
                # Get the kubeconfig secret name (same approach as download-kubeconfigs.sh)
                local kubeconfig_secret=$(oc get secret -n "$cluster" -o name | grep -E "(admin-kubeconfig|kubeconfig)" | head -1)
                
                if [[ -z "$kubeconfig_secret" ]]; then
                  echo "No kubeconfig secret found for cluster $cluster"
                  return 1
                fi
                
                echo "Found kubeconfig secret: $kubeconfig_secret"
                
                # Try to get the kubeconfig data (same approach as download-kubeconfigs.sh)
                local kubeconfig_data=""
                
                # First try to get the 'kubeconfig' field
                kubeconfig_data=$(oc get "$kubeconfig_secret" -n "$cluster" -o jsonpath='{.data.kubeconfig}' 2>/dev/null | base64 -d 2>/dev/null || echo "")
                
                # If that fails, try the 'raw-kubeconfig' field
                if [[ -z "$kubeconfig_data" ]]; then
                  kubeconfig_data=$(oc get "$kubeconfig_secret" -n "$cluster" -o jsonpath='{.data.raw-kubeconfig}' 2>/dev/null | base64 -d 2>/dev/null || echo "")
                fi
                
                if [[ -z "$kubeconfig_data" ]]; then
                  echo "Could not extract kubeconfig data for cluster $cluster"
                  return 1
                fi
                
                # Write the kubeconfig to file
                echo "$kubeconfig_data" > "$kubeconfig_path"
                
                # Validate kubeconfig (same as download-kubeconfigs.sh)
                if oc --kubeconfig="$kubeconfig_path" get nodes &>/dev/null; then
                  echo "Kubeconfig downloaded and validated for $cluster"
                  
                  # Show cluster info (same as download-kubeconfigs.sh)
                  local server_url=$(echo "$kubeconfig_data" | grep -E "^\s*server:" | head -1 | awk '{print $2}' || echo "Unknown")
                  echo "  Server URL: $server_url"
                  
                  local node_count=$(oc --kubeconfig="$kubeconfig_path" get nodes --no-headers 2>/dev/null | wc -l || echo "0")
                  echo "  Node count: $node_count"
                  
                  return 0
                else
                  echo "Downloaded kubeconfig for $cluster but it may not be valid"
                  echo "  File saved as: $kubeconfig_path"
                  return 1
                fi
              }
          
          # Main monitoring loop
          attempt=1
          while [[ $attempt -le $MAX_ATTEMPTS ]]; do
            echo "=== ArgoCD Health Check Attempt $attempt/$MAX_ATTEMPTS ==="
            
            # Get list of managed clusters
            MANAGED_CLUSTERS=$(oc get managedclusters -o jsonpath='{.items[*].metadata.name}' 2>/dev/null || echo "")
            
            if [[ -z "$MANAGED_CLUSTERS" ]]; then
              echo "No managed clusters found"
              sleep $SLEEP_INTERVAL
              ((attempt++))
              continue
            fi
            
            echo "Found managed clusters: $MANAGED_CLUSTERS"
            
            wedged_clusters=()
            
            # First, check if all managed clusters are available and ready
            echo "üîç Checking if all managed clusters are available and ready..."
            unavailable_clusters=()
            for cluster in $MANAGED_CLUSTERS; do
              if [[ "$cluster" == "local-cluster" ]]; then
                continue
              fi
              
              echo "Checking availability of cluster: $cluster"
              
              # Check if cluster is available
              cluster_status=$(oc get managedcluster "$cluster" -o jsonpath='{.status.conditions[?(@.type=="ManagedClusterConditionAvailable")].status}' 2>/dev/null || echo "Unknown")
              if [[ "$cluster_status" != "True" ]]; then
                echo "‚ö†Ô∏è  Cluster $cluster is not available (status: $cluster_status)"
                unavailable_clusters+=("$cluster")
                continue
              fi
              
              # Check if cluster is joined
              joined_status=$(oc get managedcluster "$cluster" -o jsonpath='{.status.conditions[?(@.type=="ManagedClusterJoined")].status}' 2>/dev/null || echo "Unknown")
              if [[ "$joined_status" != "True" ]]; then
                echo "‚ö†Ô∏è  Cluster $cluster is not joined (status: $joined_status)"
                unavailable_clusters+=("$cluster")
                continue
              fi
              
              echo "‚úÖ Cluster $cluster is available and joined"
            done
            
            # If any clusters are not ready, wait and retry
            if [[ ${#unavailable_clusters[@]} -gt 0 ]]; then
              echo "‚è≥ Waiting for clusters to be ready: ${unavailable_clusters[*]}"
              echo "Clusters must be available and joined before health checks can begin"
              sleep $SLEEP_INTERVAL
              ((attempt++))
              continue
            fi
            
            echo "‚úÖ All managed clusters are available and ready - proceeding with health checks"
            
            # Now check each managed cluster for ArgoCD health
            kubeconfig_failures=()
            for cluster in $MANAGED_CLUSTERS; do
              if [[ "$cluster" == "local-cluster" ]]; then
                continue
              fi
              
              echo "Checking ArgoCD health on cluster: $cluster"
              
              # Download kubeconfig
              if download_kubeconfig "$cluster"; then
                kubeconfig_path="/tmp/${cluster}-kubeconfig.yaml"
                
                # Check if cluster is wedged
                if check_cluster_wedged "$cluster" "$kubeconfig_path"; then
                  wedged_clusters+=("$cluster")
                fi
              else
                echo "‚ùå Failed to download or validate kubeconfig for $cluster"
                kubeconfig_failures+=("$cluster")
              fi
            done
            
            # If there are kubeconfig failures, this is a critical error
            if [[ ${#kubeconfig_failures[@]} -gt 0 ]]; then
              echo "‚ùå Critical error: Cannot access clusters due to kubeconfig issues: ${kubeconfig_failures[*]}"
              echo "This indicates a problem with cluster connectivity or kubeconfig secrets"
              echo "The health monitor cannot function without valid kubeconfigs"
              exit 1
            fi
            
            # Remediate wedged clusters
            if [[ ${#wedged_clusters[@]} -gt 0 ]]; then
              echo "Found wedged clusters: ${wedged_clusters[*]}"
              
              for cluster in "${wedged_clusters[@]}"; do
                kubeconfig_path="/tmp/${cluster}-kubeconfig.yaml"
                remediate_wedged_cluster "$cluster" "$kubeconfig_path"
              done
              
              echo "‚úÖ Remediation completed for wedged clusters"
            else
              echo "‚úÖ All clusters are healthy"
            fi
            
            # Wait before next check
            if [[ $attempt -lt $MAX_ATTEMPTS ]]; then
              echo "Waiting $SLEEP_INTERVAL seconds before next check..."
              sleep $SLEEP_INTERVAL
            fi
            
            ((attempt++))
          done
          
          echo "üéâ ArgoCD health monitoring completed"
      serviceAccountName: argocd-health-monitor
