apiVersion: batch/v1
kind: Job
metadata:
  name: odf-ssl-certificate-extractor
  namespace: openshift-config
  labels:
    app.kubernetes.io/name: odf-ssl-certificate-management
    app.kubernetes.io/component: certificate-extraction
  annotations:
    argocd.argoproj.io/sync-wave: "1"
    argocd.argoproj.io/sync-options: Prune=false
    argocd.argoproj.io/compare-options: IgnoreExtraneous
spec:
  template:
    spec:
      containers:
      - name: odf-ssl-extractor
        image: registry.redhat.io/openshift4/ose-cli:latest
        resources:
          requests:
            memory: "512Mi"
            cpu: "200m"
          limits:
            memory: "1Gi"
            cpu: "500m"
        command:
        - /bin/bash
        - -c
        - |
          set -euo pipefail
          
          echo "Starting ODF SSL certificate extraction and distribution..."
          echo "Following Red Hat ODF Disaster Recovery certificate management guidelines"
          
          # Configuration for retry logic
          MAX_RETRIES=5
          BASE_DELAY=30
          MAX_DELAY=300
          RETRY_COUNT=0
          
          # Function to implement exponential backoff
          exponential_backoff() {
            local delay=$((BASE_DELAY * (2 ** RETRY_COUNT)))
            if [[ $delay -gt $MAX_DELAY ]]; then
              delay=$MAX_DELAY
            fi
            echo "‚è≥ Waiting $delay seconds before retry (attempt $((RETRY_COUNT + 1))/$MAX_RETRIES)..."
            sleep $delay
            ((RETRY_COUNT++))
          }
          
          # Function to handle errors gracefully
          handle_error() {
            local error_msg="$1"
            echo "‚ùå Error: $error_msg"
            
            if [[ $RETRY_COUNT -lt $MAX_RETRIES ]]; then
              echo "üîÑ Retrying in a moment..."
              exponential_backoff
              return 0
            else
              echo "üí• Max retries exceeded. Job will exit but ArgoCD can retry the sync."
              echo "   This is a temporary failure - the job will be retried on next ArgoCD sync."
              exit 1
            fi
          }
          
          # Main execution with retry logic
          main_execution() {
            # Create working directory
            WORK_DIR="/tmp/odf-ssl-certs"
            mkdir -p "$WORK_DIR"
          
          # Function to extract CA from cluster
          extract_cluster_ca() {
            cluster_name="$1"
            output_file="$2"
            kubeconfig="${3:-}"
            
            echo "Extracting CA from cluster: $cluster_name"
            
            if [[ -n "$kubeconfig" && -f "$kubeconfig" ]]; then
              # Use provided kubeconfig
              echo "  Using kubeconfig: $kubeconfig"
              if oc --kubeconfig="$kubeconfig" get configmap -n openshift-config-managed trusted-ca-bundle -o jsonpath="{.data['ca-bundle\.crt']}" > "$output_file" 2>/dev/null; then
                if [[ -s "$output_file" ]]; then
                  echo "  CA extracted from $cluster_name using kubeconfig"
                  return 0
                else
                  echo "  CA file is empty from $cluster_name"
                  return 1
                fi
              else
                echo "  Failed to get trusted-ca-bundle from $cluster_name"
                return 1
              fi
            else
              # Use current context (hub cluster)
              echo "  Using current context for hub cluster"
              if oc get configmap -n openshift-config-managed trusted-ca-bundle -o jsonpath="{.data['ca-bundle\.crt']}" > "$output_file" 2>/dev/null; then
                if [[ -s "$output_file" ]]; then
                  echo "  CA extracted from $cluster_name using current context"
                  return 0
                else
                  echo "  CA file is empty from $cluster_name"
                  return 1
                fi
              else
                echo "  Failed to get trusted-ca-bundle from $cluster_name"
                return 1
              fi
            fi
          }
          
          # Function to extract ingress CA from cluster
          extract_ingress_ca() {
            cluster_name="$1"
            output_file="$2"
            kubeconfig="${3:-}"
            
            echo "Extracting ingress CA from cluster: $cluster_name"
            
            if [[ -n "$kubeconfig" && -f "$kubeconfig" ]]; then
              # Use provided kubeconfig
              echo "  Using kubeconfig: $kubeconfig"
              # Try to get ingress CA from router-ca secret
              if oc --kubeconfig="$kubeconfig" get secret -n openshift-ingress-operator router-ca -o jsonpath='{.data.tls\.crt}' 2>/dev/null | base64 -d > "$output_file" 2>/dev/null; then
                if [[ -s "$output_file" ]]; then
                  echo "  Ingress CA extracted from $cluster_name using kubeconfig"
                  return 0
                fi
              fi
              # Fallback: try to get from ingress operator config
              if oc --kubeconfig="$kubeconfig" get secret -n openshift-ingress-operator router-ca -o jsonpath='{.data.ca\.crt}' 2>/dev/null | base64 -d > "$output_file" 2>/dev/null; then
                if [[ -s "$output_file" ]]; then
                  echo "  Ingress CA extracted from $cluster_name using kubeconfig (fallback)"
                  return 0
                fi
              fi
              echo "  Failed to get ingress CA from $cluster_name"
              return 1
            else
              # Use current context (hub cluster)
              echo "  Using current context for hub cluster"
              # Try to get ingress CA from router-ca secret
              if oc get secret -n openshift-ingress-operator router-ca -o jsonpath='{.data.tls\.crt}' 2>/dev/null | base64 -d > "$output_file" 2>/dev/null; then
                if [[ -s "$output_file" ]]; then
                  echo "  Ingress CA extracted from $cluster_name using current context"
                  return 0
                fi
              fi
              # Fallback: try to get from ingress operator config
              if oc get secret -n openshift-ingress-operator router-ca -o jsonpath='{.data.ca\.crt}' 2>/dev/null | base64 -d > "$output_file" 2>/dev/null; then
                if [[ -s "$output_file" ]]; then
                  echo "  Ingress CA extracted from $cluster_name using current context (fallback)"
                  return 0
                fi
              fi
              echo "  Failed to get ingress CA from $cluster_name"
              return 1
            fi
          }
          
          # Function to create combined CA bundle
          create_combined_ca_bundle() {
            output_file="$1"
            shift
            ca_files=("$@")
            
            echo "Creating combined CA bundle..."
            > "$output_file"
            
            file_count=0
            for ca_file in "${ca_files[@]}"; do
              if [[ -f "$ca_file" && -s "$ca_file" ]]; then
                echo "# CA from $(basename "$ca_file" .crt)" >> "$output_file"
                
                # Extract only the first few complete certificates to avoid size limits
                cert_count=0
                in_cert=false
                while IFS= read -r line; do
                  if [[ "$line" == "-----BEGIN CERTIFICATE-----" ]]; then
                    in_cert=true
                    cert_count=$((cert_count + 1))
                    if [[ $cert_count -gt 5 ]]; then
                      break
                    fi
                  fi
                  if [[ $in_cert == true ]]; then
                    echo "$line" >> "$output_file"
                  fi
                  if [[ "$line" == "-----END CERTIFICATE-----" ]]; then
                    in_cert=false
                    echo "" >> "$output_file"
                  fi
                done < "$ca_file"
                
                file_count=$((file_count + 1))
              fi
            done
            
            if [[ $file_count -gt 0 ]]; then
              echo "Combined CA bundle created with $file_count CA sources (first 5 certs each)"
              return 0
            else
              echo "No valid CA files found to combine"
              return 1
            fi
          }
          
          # Extract hub cluster CA
          echo "1. Extracting hub cluster CA..."
          if extract_cluster_ca "hub" "$WORK_DIR/hub-ca.crt"; then
            echo "  Hub cluster CA extracted successfully"
            echo "  Certificate size: $(wc -c < "$WORK_DIR/hub-ca.crt") bytes"
            echo "  First few lines:"
            head -n 5 "$WORK_DIR/hub-ca.crt"
          else
            echo "  Failed to extract hub cluster CA"
            echo "  Job will continue with managed cluster certificates only"
          fi
          
          # Extract hub cluster ingress CA
          echo "1b. Extracting hub cluster ingress CA..."
          if extract_ingress_ca "hub" "$WORK_DIR/hub-ingress-ca.crt"; then
            echo "  Hub cluster ingress CA extracted successfully"
            echo "  Certificate size: $(wc -c < "$WORK_DIR/hub-ingress-ca.crt") bytes"
          else
            echo "  Failed to extract hub cluster ingress CA"
            echo "  Job will continue without hub ingress CA"
          fi
          
          # Get managed clusters
          echo "2. Discovering managed clusters..."
          MANAGED_CLUSTERS=$(oc get managedclusters -o jsonpath='{.items[*].metadata.name}' 2>/dev/null || echo "")
          
          if [[ -z "$MANAGED_CLUSTERS" ]]; then
            echo "  No managed clusters found"
          else
            echo "  Found managed clusters: $MANAGED_CLUSTERS"
          fi
          
          # Extract CA from each managed cluster
          CA_FILES=()
          REQUIRED_CLUSTERS=("hub" "ocp-primary" "ocp-secondary")
          EXTRACTED_CLUSTERS=()
          
          # Track hub cluster CA extraction
          if [[ -f "$WORK_DIR/hub-ca.crt" && -s "$WORK_DIR/hub-ca.crt" ]]; then
            CA_FILES+=("$WORK_DIR/hub-ca.crt")
            EXTRACTED_CLUSTERS+=("hub")
            echo "  Added hub CA to bundle"
          else
            echo "  ‚ùå Hub CA not available - REQUIRED for DR setup"
          fi
          
          if [[ -f "$WORK_DIR/hub-ingress-ca.crt" && -s "$WORK_DIR/hub-ingress-ca.crt" ]]; then
            CA_FILES+=("$WORK_DIR/hub-ingress-ca.crt")
            echo "  Added hub ingress CA to bundle"
          else
            echo "  Hub ingress CA not available, continuing without it"
          fi
          
          index=1
          
          for cluster in $MANAGED_CLUSTERS; do
            if [[ "$cluster" == "local-cluster" ]]; then
              continue
            fi
            
            echo "3.$index Extracting CA from $cluster..."
            
            # Try to get kubeconfig for the cluster
            KUBECONFIG_FILE=""
            if oc get secret -n "$cluster" -o name | grep -E "(admin-kubeconfig|kubeconfig)" | head -1 | xargs -I {} oc get {} -n "$cluster" -o jsonpath='{.data.kubeconfig}' | base64 -d > "$WORK_DIR/${cluster}-kubeconfig.yaml" 2>/dev/null; then
              KUBECONFIG_FILE="$WORK_DIR/${cluster}-kubeconfig.yaml"
            fi
            
            cluster_ca_extracted=false
            if extract_cluster_ca "$cluster" "$WORK_DIR/${cluster}-ca.crt" "$KUBECONFIG_FILE"; then
              CA_FILES+=("$WORK_DIR/${cluster}-ca.crt")
              EXTRACTED_CLUSTERS+=("$cluster")
              cluster_ca_extracted=true
              echo "  Certificate size: $(wc -c < "$WORK_DIR/${cluster}-ca.crt") bytes"
            else
              echo "  ‚ùå Could not extract CA from $cluster - REQUIRED for DR setup"
            fi
            
            # Extract ingress CA from managed cluster
            echo "3b.$index Extracting ingress CA from $cluster..."
            if extract_ingress_ca "$cluster" "$WORK_DIR/${cluster}-ingress-ca.crt" "$KUBECONFIG_FILE"; then
              CA_FILES+=("$WORK_DIR/${cluster}-ingress-ca.crt")
              echo "  Ingress CA certificate size: $(wc -c < "$WORK_DIR/${cluster}-ingress-ca.crt") bytes"
            else
              echo "  Warning: Could not extract ingress CA from $cluster, continuing without it"
            fi
            
            ((index++))
          done
          
          # Validate that we have CA material from all required clusters
          echo "4. Validating CA extraction from required clusters..."
          MISSING_CLUSTERS=()
          for required_cluster in "${REQUIRED_CLUSTERS[@]}"; do
            if [[ " ${EXTRACTED_CLUSTERS[@]} " =~ " ${required_cluster} " ]]; then
              echo "  ‚úÖ CA extracted from $required_cluster"
            else
              echo "  ‚ùå CA NOT extracted from $required_cluster"
              MISSING_CLUSTERS+=("$required_cluster")
            fi
          done
          
          if [[ ${#MISSING_CLUSTERS[@]} -gt 0 ]]; then
            echo ""
            echo "‚ùå CRITICAL ERROR: CA material missing from required clusters:"
            for missing in "${MISSING_CLUSTERS[@]}"; do
              echo "   - $missing"
            done
            echo ""
            echo "The ODF SSL certificate extractor job requires CA material from ALL three clusters:"
            echo "   - hub (hub cluster)"
            echo "   - ocp-primary (primary managed cluster)"  
            echo "   - ocp-secondary (secondary managed cluster)"
            echo ""
            echo "Without CA material from all clusters, the DR setup will fail."
            echo "Please ensure all clusters are accessible and have proper kubeconfigs."
            echo ""
            echo "Job will exit with error code 1."
            exit 1
          fi
          
          # Create combined CA bundle
          echo "5. Creating combined CA bundle..."
          echo "  CA files to combine: ${#CA_FILES[@]} files"
          for ca_file in "${CA_FILES[@]}"; do
            echo "    - $(basename "$ca_file") ($(wc -c < "$ca_file") bytes)"
          done
          
          if create_combined_ca_bundle "$WORK_DIR/combined-ca-bundle.crt" "${CA_FILES[@]}"; then
            echo "  Combined CA bundle created successfully"
            echo "  Bundle size: $(wc -c < "$WORK_DIR/combined-ca-bundle.crt") bytes"
            echo "  First few lines of bundle:"
            head -n 10 "$WORK_DIR/combined-ca-bundle.crt"
          else
            echo "  Failed to create combined CA bundle - no certificates extracted"
            echo "  Job will exit as no certificate data is available"
            exit 1
          fi
          
          # Create or update ConfigMap on hub cluster
          echo "6. Creating/updating cluster-proxy-ca-bundle ConfigMap on hub cluster..."
          
          # Check if ConfigMap exists
          if oc get configmap cluster-proxy-ca-bundle -n openshift-config >/dev/null 2>&1; then
            echo "  ConfigMap exists, patching with certificate data..."
            # Create a temporary patch file to avoid JSON escaping issues
            echo "data:" > "$WORK_DIR/patch.yaml"
            echo "  ca-bundle.crt: |" >> "$WORK_DIR/patch.yaml"
            cat "$WORK_DIR/combined-ca-bundle.crt" | sed 's/^/    /' >> "$WORK_DIR/patch.yaml"
            oc patch configmap cluster-proxy-ca-bundle -n openshift-config \
              --type=merge \
              --patch-file="$WORK_DIR/patch.yaml"
            rm -f "$WORK_DIR/patch.yaml"
          else
            echo "  ConfigMap does not exist, creating with certificate data..."
            oc create configmap cluster-proxy-ca-bundle \
              --from-file=ca-bundle.crt="$WORK_DIR/combined-ca-bundle.crt" \
              -n openshift-config
          fi
          
          echo "  ConfigMap created/updated successfully with certificate data"
          echo "  Certificate bundle contains CA certificates from hub and managed clusters"
          
          # Update hub cluster proxy
          echo "7. Updating hub cluster proxy configuration..."
          oc patch proxy/cluster --type=merge --patch='{"spec":{"trustedCA":{"name":"cluster-proxy-ca-bundle"}}}' || {
            echo "  Warning: Could not update hub cluster proxy"
          }
          
          # Restart ramenddr-cluster-operator pods on managed clusters before updating configmap
          echo "7a. Restarting ramenddr-cluster-operator pods on managed clusters..."
          
          for cluster in $MANAGED_CLUSTERS; do
            if [[ "$cluster" == "local-cluster" ]]; then
              continue
            fi
            
            echo "  Processing cluster: $cluster"
            
            # Get kubeconfig for the cluster
            KUBECONFIG_FILE=""
            if oc get secret -n "$cluster" -o name | grep -E "(admin-kubeconfig|kubeconfig)" | head -1 | xargs -I {} oc get {} -n "$cluster" -o jsonpath='{.data.kubeconfig}' | base64 -d > "$WORK_DIR/${cluster}-kubeconfig.yaml" 2>/dev/null; then
              KUBECONFIG_FILE="$WORK_DIR/${cluster}-kubeconfig.yaml"
            fi
            
            if [[ -n "$KUBECONFIG_FILE" && -f "$KUBECONFIG_FILE" ]]; then
              # Find ramenddr-cluster-operator pods
              RAMEN_PODS=$(oc --kubeconfig="$KUBECONFIG_FILE" get pods -n openshift-dr-system -l app=ramenddr-cluster-operator -o jsonpath='{.items[*].metadata.name}' 2>/dev/null || echo "")
              
              if [[ -n "$RAMEN_PODS" ]]; then
                echo "    Found ramenddr-cluster-operator pods: $RAMEN_PODS"
                
                for pod in $RAMEN_PODS; do
                  echo "    Deleting pod $pod to trigger restart..."
                  oc --kubeconfig="$KUBECONFIG_FILE" delete pod "$pod" -n openshift-dr-system --ignore-not-found=true || {
                    echo "    Warning: Could not delete pod $pod"
                  }
                done
                
                # Wait for pods to be deleted
                echo "    Waiting for pods to be terminated..."
                for pod in $RAMEN_PODS; do
                  oc --kubeconfig="$KUBECONFIG_FILE" wait --for=delete pod/"$pod" -n openshift-dr-system --timeout=60s 2>/dev/null || true
                done
                
                # Wait for new pods to be running
                echo "    Waiting for new ramenddr-cluster-operator pods to be running..."
                MAX_WAIT_ATTEMPTS=30
                WAIT_INTERVAL=10
                attempt=0
                
                while [[ $attempt -lt $MAX_WAIT_ATTEMPTS ]]; do
                  attempt=$((attempt + 1))
                  
                  NEW_PODS=$(oc --kubeconfig="$KUBECONFIG_FILE" get pods -n openshift-dr-system -l app=ramenddr-cluster-operator -o jsonpath='{.items[*].metadata.name}' 2>/dev/null || echo "")
                  ALL_RUNNING=true
                  
                  if [[ -n "$NEW_PODS" ]]; then
                    for pod in $NEW_PODS; do
                      POD_STATUS=$(oc --kubeconfig="$KUBECONFIG_FILE" get pod "$pod" -n openshift-dr-system -o jsonpath='{.status.phase}' 2>/dev/null || echo "Unknown")
                      
                      if [[ "$POD_STATUS" != "Running" ]]; then
                        ALL_RUNNING=false
                        break
                      fi
                    done
                    
                    if [[ "$ALL_RUNNING" == "true" ]]; then
                      echo "    ‚úÖ All ramenddr-cluster-operator pods are running on $cluster: $NEW_PODS"
                      break
                    else
                      echo "    ‚è≥ Waiting for pods to be running (attempt $attempt/$MAX_WAIT_ATTEMPTS)"
                    fi
                  else
                    echo "    ‚è≥ Waiting for pods to appear (attempt $attempt/$MAX_WAIT_ATTEMPTS)"
                  fi
                  
                  if [[ $attempt -lt $MAX_WAIT_ATTEMPTS ]]; then
                    sleep $WAIT_INTERVAL
                  fi
                done
                
                if [[ $attempt -ge $MAX_WAIT_ATTEMPTS ]]; then
                  echo "    ‚ö†Ô∏è  Warning: ramenddr-cluster-operator pods did not become ready within expected time on $cluster"
                  echo "     The pods may still be starting - configuration changes will be applied when ready"
                fi
              else
                echo "    ‚ö†Ô∏è  Warning: ramenddr-cluster-operator pods not found on $cluster - they may not be deployed yet"
                echo "     Configuration changes will be applied when the pods start"
              fi
            else
              echo "    ‚ùå Could not get kubeconfig for $cluster - skipping pod restart"
            fi
          done
          
          echo "  ‚úÖ Completed ramenddr-cluster-operator pod restarts on managed clusters"
          
          # Update ramen-hub-operator-config with base64-encoded CA bundle
          echo "7b. Updating ramen-hub-operator-config in openshift-operators namespace..."
          
          # Base64 encode the combined CA bundle
          CA_BUNDLE_BASE64=$(base64 -w 0 < "$WORK_DIR/combined-ca-bundle.crt" 2>/dev/null || base64 < "$WORK_DIR/combined-ca-bundle.crt" | tr -d '\n')
          
          # Check if ramen-hub-operator-config exists
          if oc get configmap ramen-hub-operator-config -n openshift-operators &>/dev/null; then
            echo "  ConfigMap exists, updating ramen_manager_config.yaml with caCertificates..."
            
            # Get existing ramen_manager_config.yaml content
            EXISTING_YAML=$(oc get configmap ramen-hub-operator-config -n openshift-operators -o jsonpath='{.data.ramen_manager_config\.yaml}' 2>/dev/null || echo "")
            
            # Create updated YAML with caCertificates
            if [[ -n "$EXISTING_YAML" ]]; then
              # Use yq to merge caCertificates into existing YAML, or use a simple approach
              # Create a temporary YAML file with the update
              echo "$EXISTING_YAML" > "$WORK_DIR/existing-ramen-config.yaml"
              
              # Add or update caCertificates in the YAML
              # Check if caCertificates already exists
              if grep -q "^caCertificates:" "$WORK_DIR/existing-ramen-config.yaml"; then
                # Update existing caCertificates
                if command -v yq &>/dev/null; then
                  yq eval ".caCertificates = \"$CA_BUNDLE_BASE64\"" -i "$WORK_DIR/existing-ramen-config.yaml"
                else
                  # Fallback: use sed to update the line
                  sed -i "s/^caCertificates:.*/caCertificates: $CA_BUNDLE_BASE64/" "$WORK_DIR/existing-ramen-config.yaml"
                fi
              else
                # Add new caCertificates at the end
                echo "caCertificates: $CA_BUNDLE_BASE64" >> "$WORK_DIR/existing-ramen-config.yaml"
              fi
              
              UPDATED_YAML=$(cat "$WORK_DIR/existing-ramen-config.yaml")
            else
              # No existing YAML, create new one with just caCertificates
              UPDATED_YAML="caCertificates: $CA_BUNDLE_BASE64"
            fi
            
            # Create patch file for ConfigMap update
            echo "data:" > "$WORK_DIR/ramen-patch.yaml"
            echo "  ramen_manager_config.yaml: |" >> "$WORK_DIR/ramen-patch.yaml"
            echo "$UPDATED_YAML" | sed 's/^/    /' >> "$WORK_DIR/ramen-patch.yaml"
            
            # Patch the ConfigMap with updated YAML
            oc patch configmap ramen-hub-operator-config -n openshift-operators \
              --type=merge \
              --patch-file="$WORK_DIR/ramen-patch.yaml" || {
              echo "  Warning: Could not patch ramen-hub-operator-config"
            }
            
            rm -f "$WORK_DIR/ramen-patch.yaml"
            
          else
            echo "  ConfigMap does not exist, creating with ramen_manager_config.yaml containing caCertificates..."
            oc create configmap ramen-hub-operator-config -n openshift-operators \
              --from-literal=ramen_manager_config.yaml="caCertificates: $CA_BUNDLE_BASE64" || {
              echo "  Warning: Could not create ramen-hub-operator-config"
            }
          fi
          
          echo "  ramen-hub-operator-config updated successfully with base64-encoded CA bundle"
          echo "  This enables SSL access for discovered applications in ODF Disaster Recovery"
          
          # Update ramen-dr-cluster-operator-config on managed clusters with base64-encoded CA bundle
          echo "7c. Updating ramen-dr-cluster-operator-config on managed clusters..."
          
          # Base64 encode the combined CA bundle (already done, but ensure it's available)
          CA_BUNDLE_BASE64=$(base64 -w 0 < "$WORK_DIR/combined-ca-bundle.crt" 2>/dev/null || base64 < "$WORK_DIR/combined-ca-bundle.crt" | tr -d '\n')
          
          for cluster in $MANAGED_CLUSTERS; do
            if [[ "$cluster" == "local-cluster" ]]; then
              continue
            fi
            
            echo "  Processing cluster: $cluster"
            
            # Get kubeconfig for the cluster
            KUBECONFIG_FILE=""
            if oc get secret -n "$cluster" -o name | grep -E "(admin-kubeconfig|kubeconfig)" | head -1 | xargs -I {} oc get {} -n "$cluster" -o jsonpath='{.data.kubeconfig}' | base64 -d > "$WORK_DIR/${cluster}-kubeconfig.yaml" 2>/dev/null; then
              KUBECONFIG_FILE="$WORK_DIR/${cluster}-kubeconfig.yaml"
            fi
            
            if [[ -n "$KUBECONFIG_FILE" && -f "$KUBECONFIG_FILE" ]]; then
              # Check if ramen-dr-cluster-operator-config exists
              if oc --kubeconfig="$KUBECONFIG_FILE" get configmap ramen-dr-cluster-operator-config -n openshift-dr-system &>/dev/null; then
                echo "    ConfigMap exists, updating ramen_manager_config.yaml with caCertificates..."
                
                # Get existing ramen_manager_config.yaml content
                EXISTING_YAML=$(oc --kubeconfig="$KUBECONFIG_FILE" get configmap ramen-dr-cluster-operator-config -n openshift-dr-system -o jsonpath='{.data.ramen_manager_config\.yaml}' 2>/dev/null || echo "")
                
                # Create updated YAML with caCertificates
                if [[ -n "$EXISTING_YAML" ]]; then
                  # Create a temporary YAML file with the update
                  echo "$EXISTING_YAML" > "$WORK_DIR/${cluster}-existing-ramen-config.yaml"
                  
                  # Add or update caCertificates in the YAML
                  # Check if caCertificates already exists (handle both with and without spaces)
                  if grep -qE "^caCertificates[[:space:]]*:" "$WORK_DIR/${cluster}-existing-ramen-config.yaml"; then
                    # Update existing caCertificates
                    if command -v yq &>/dev/null; then
                      yq eval ".caCertificates = \"$CA_BUNDLE_BASE64\"" -i "$WORK_DIR/${cluster}-existing-ramen-config.yaml" 2>/dev/null || {
                        # Fallback: use sed to update the line
                        sed -i "s|^caCertificates[[:space:]]*:.*|caCertificates: \"$CA_BUNDLE_BASE64\"|" "$WORK_DIR/${cluster}-existing-ramen-config.yaml"
                      }
                    else
                      # Use sed to update the line - match the pattern and replace with quoted value
                      sed -i "s|^caCertificates[[:space:]]*:.*|caCertificates: \"$CA_BUNDLE_BASE64\"|" "$WORK_DIR/${cluster}-existing-ramen-config.yaml"
                    fi
                  else
                    # Add new caCertificates at the end (ensure it's on a new line)
                    echo "" >> "$WORK_DIR/${cluster}-existing-ramen-config.yaml"
                    echo "caCertificates: \"$CA_BUNDLE_BASE64\"" >> "$WORK_DIR/${cluster}-existing-ramen-config.yaml"
                  fi
                  
                  UPDATED_YAML=$(cat "$WORK_DIR/${cluster}-existing-ramen-config.yaml")
                else
                  # No existing YAML, create new one with just caCertificates (quoted)
                  UPDATED_YAML="caCertificates: \"$CA_BUNDLE_BASE64\""
                fi
                
                # Create patch file for ConfigMap update
                echo "data:" > "$WORK_DIR/${cluster}-ramen-patch.yaml"
                echo "  ramen_manager_config.yaml: |" >> "$WORK_DIR/${cluster}-ramen-patch.yaml"
                echo "$UPDATED_YAML" | sed 's/^/    /' >> "$WORK_DIR/${cluster}-ramen-patch.yaml"
                
                # Patch the ConfigMap with updated YAML
                if oc --kubeconfig="$KUBECONFIG_FILE" patch configmap ramen-dr-cluster-operator-config -n openshift-dr-system \
                  --type=merge \
                  --patch-file="$WORK_DIR/${cluster}-ramen-patch.yaml" 2>&1; then
                  
                  # Verify the patch was successful
                  sleep 2
                  VERIFIED_YAML=$(oc --kubeconfig="$KUBECONFIG_FILE" get configmap ramen-dr-cluster-operator-config -n openshift-dr-system -o jsonpath='{.data.ramen_manager_config\.yaml}' 2>/dev/null || echo "")
                  
                  if echo "$VERIFIED_YAML" | grep -qE "caCertificates[[:space:]]*:" && echo "$VERIFIED_YAML" | grep -q "$CA_BUNDLE_BASE64"; then
                    echo "    ‚úÖ ramen-dr-cluster-operator-config updated and verified successfully on $cluster"
                  else
                    echo "    ‚ö†Ô∏è  Warning: ramen-dr-cluster-operator-config patched but verification failed on $cluster"
                    echo "     The caCertificates field may not have been set correctly"
                    echo "     Current YAML content:"
                    echo "$VERIFIED_YAML" | head -n 5
                  fi
                else
                  echo "    ‚ùå Error: Could not patch ramen-dr-cluster-operator-config on $cluster"
                  echo "     Attempting alternative approach using oc apply..."
                  
                  # Alternative: Use oc apply with the patch file
                  if oc --kubeconfig="$KUBECONFIG_FILE" apply -f "$WORK_DIR/${cluster}-ramen-patch.yaml" 2>&1; then
                    # Verify the patch was successful
                    sleep 2
                    VERIFIED_YAML=$(oc --kubeconfig="$KUBECONFIG_FILE" get configmap ramen-dr-cluster-operator-config -n openshift-dr-system -o jsonpath='{.data.ramen_manager_config\.yaml}' 2>/dev/null || echo "")
                    
                    if echo "$VERIFIED_YAML" | grep -qE "caCertificates[[:space:]]*:" && echo "$VERIFIED_YAML" | grep -q "$CA_BUNDLE_BASE64"; then
                      echo "    ‚úÖ ramen-dr-cluster-operator-config updated using alternative approach on $cluster"
                    else
                      echo "    ‚ö†Ô∏è  Warning: Alternative approach applied but verification failed on $cluster"
                      echo "     The caCertificates field may not have been set correctly"
                    fi
                  else
                    echo "    ‚ùå Alternative approach also failed on $cluster"
                    echo "     Manual intervention may be required to set caCertificates"
                  fi
                fi
                
                rm -f "$WORK_DIR/${cluster}-existing-ramen-config.yaml" "$WORK_DIR/${cluster}-ramen-patch.yaml"
              else
                echo "    ‚ö†Ô∏è  Warning: ramen-dr-cluster-operator-config not found on $cluster - it may not be deployed yet"
                echo "     Configuration changes will be applied when the ConfigMap is created"
              fi
            else
              echo "    ‚ùå Could not get kubeconfig for $cluster - skipping ConfigMap update"
            fi
          done
          
          echo "  ‚úÖ Completed ramen-dr-cluster-operator-config updates on managed clusters"
          
          # Distribute certificate data to managed clusters with retry logic
          echo "8. Distributing certificate data to managed clusters..."
          DISTRIBUTION_ATTEMPTS=3
          DISTRIBUTION_SLEEP=10
          
          for cluster in $MANAGED_CLUSTERS; do
            if [[ "$cluster" == "local-cluster" ]]; then
              continue
            fi
            
            echo "  Distributing to $cluster..."
            
            # Get kubeconfig for the cluster
            KUBECONFIG_FILE=""
            if oc get secret -n "$cluster" -o name | grep -E "(admin-kubeconfig|kubeconfig)" | head -1 | xargs -I {} oc get {} -n "$cluster" -o jsonpath='{.data.kubeconfig}' | base64 -d > "$WORK_DIR/${cluster}-kubeconfig.yaml" 2>/dev/null; then
              KUBECONFIG_FILE="$WORK_DIR/${cluster}-kubeconfig.yaml"
            fi
            
            if [[ -n "$KUBECONFIG_FILE" && -f "$KUBECONFIG_FILE" ]]; then
              # Retry distribution to managed cluster
              distribution_success=false
              for dist_attempt in $(seq 1 $DISTRIBUTION_ATTEMPTS); do
                echo "    Distribution attempt $dist_attempt/$DISTRIBUTION_ATTEMPTS for $cluster..."
                
                # Create ConfigMap on managed cluster
                if oc --kubeconfig="$KUBECONFIG_FILE" create configmap cluster-proxy-ca-bundle \
                  --from-file=ca-bundle.crt="$WORK_DIR/combined-ca-bundle.crt" \
                  -n openshift-config \
                  --dry-run=client -o yaml | oc --kubeconfig="$KUBECONFIG_FILE" apply -f -; then
                  
                  # Update managed cluster proxy
                  if oc --kubeconfig="$KUBECONFIG_FILE" patch proxy/cluster --type=merge --patch='{"spec":{"trustedCA":{"name":"cluster-proxy-ca-bundle"}}}'; then
                    echo "    ‚úÖ Certificate data distributed to $cluster (attempt $dist_attempt)"
                    distribution_success=true
                    break
                  else
                    echo "    ‚ö†Ô∏è  ConfigMap created but proxy update failed for $cluster (attempt $dist_attempt)"
                  fi
                else
                  echo "    ‚ö†Ô∏è  ConfigMap creation failed for $cluster (attempt $dist_attempt)"
                fi
                
                if [[ $dist_attempt -lt $DISTRIBUTION_ATTEMPTS ]]; then
                  echo "    ‚è≥ Waiting $DISTRIBUTION_SLEEP seconds before retry..."
                  sleep $DISTRIBUTION_SLEEP
                fi
              done
              
              if [[ "$distribution_success" != "true" ]]; then
                echo "    ‚ùå Failed to distribute certificate data to $cluster after $DISTRIBUTION_ATTEMPTS attempts"
                echo "    This may cause DR prerequisites check to fail"
              fi
            else
              echo "    ‚ùå Could not get kubeconfig for $cluster - skipping distribution"
            fi
          done
          
          # Verify distribution to managed clusters
          echo "9. Verifying certificate distribution to managed clusters..."
          verification_failed=false
          REQUIRED_VERIFICATION_CLUSTERS=("ocp-primary" "ocp-secondary")
          VERIFIED_CLUSTERS=()
          
          for cluster in $MANAGED_CLUSTERS; do
            if [[ "$cluster" == "local-cluster" ]]; then
              continue
            fi
            
            echo "  Verifying distribution to $cluster..."
            KUBECONFIG_FILE="$WORK_DIR/${cluster}-kubeconfig.yaml"
            
            if [[ -f "$KUBECONFIG_FILE" ]]; then
              # Check if ConfigMap exists and has content
              configmap_exists=$(oc --kubeconfig="$KUBECONFIG_FILE" get configmap cluster-proxy-ca-bundle -n openshift-config &>/dev/null && echo "true" || echo "false")
              configmap_size=$(oc --kubeconfig="$KUBECONFIG_FILE" get configmap cluster-proxy-ca-bundle -n openshift-config -o jsonpath='{.data.ca-bundle\.crt}' 2>/dev/null | wc -c || echo "0")
              proxy_configured=$(oc --kubeconfig="$KUBECONFIG_FILE" get proxy cluster -o jsonpath='{.spec.trustedCA.name}' 2>/dev/null || echo "")
              
              if [[ "$configmap_exists" == "true" && $configmap_size -gt 100 && "$proxy_configured" == "cluster-proxy-ca-bundle" ]]; then
                echo "    ‚úÖ $cluster: ConfigMap exists (${configmap_size} bytes), proxy configured"
                VERIFIED_CLUSTERS+=("$cluster")
              else
                echo "    ‚ùå $cluster: ConfigMap verification failed"
                echo "      ConfigMap exists: $configmap_exists"
                echo "      ConfigMap size: $configmap_size bytes"
                echo "      Proxy configured: $proxy_configured"
                verification_failed=true
              fi
            else
              echo "    ‚ùå $cluster: No kubeconfig available for verification"
              verification_failed=true
            fi
          done
          
          # Check if all required clusters are verified
          echo "10. Validating verification results..."
          MISSING_VERIFICATION_CLUSTERS=()
          for required_cluster in "${REQUIRED_VERIFICATION_CLUSTERS[@]}"; do
            if [[ " ${VERIFIED_CLUSTERS[@]} " =~ " ${required_cluster} " ]]; then
              echo "  ‚úÖ $required_cluster: Certificate distribution verified"
            else
              echo "  ‚ùå $required_cluster: Certificate distribution NOT verified"
              MISSING_VERIFICATION_CLUSTERS+=("$required_cluster")
            fi
          done
          
          if [[ ${#MISSING_VERIFICATION_CLUSTERS[@]} -gt 0 ]]; then
            echo ""
            echo "‚ùå CRITICAL ERROR: Certificate distribution verification failed for required clusters:"
            for missing in "${MISSING_VERIFICATION_CLUSTERS[@]}"; do
              echo "   - $missing"
            done
            echo ""
            echo "The ODF SSL certificate extractor job requires successful certificate distribution"
            echo "to ALL managed clusters (ocp-primary and ocp-secondary)."
            echo ""
            echo "Without proper certificate distribution, the DR setup will fail."
            echo "Please check cluster connectivity and kubeconfig availability."
            echo ""
            echo "Job will exit with error code 1."
            exit 1
          fi
          
          if [[ "$verification_failed" == "true" ]]; then
            echo ""
            echo "‚ö†Ô∏è  Certificate distribution verification failed for some clusters"
            echo "   This may cause DR prerequisites check to fail"
            echo "   Manual intervention may be required"
            echo ""
            echo "Job will exit with error code 1."
            exit 1
          else
            echo ""
            echo "‚úÖ All managed clusters verified successfully"
          fi
          
          echo ""
          echo "‚úÖ ODF SSL certificate management completed successfully!"
          echo "   - Hub cluster CA bundle: Updated (includes trusted CA + ingress CA)"
          echo "   - Hub cluster proxy: Configured"
          echo "   - Managed clusters: ramenddr-cluster-operator pods restarted"
          echo "   - ramen-hub-operator-config: Updated with base64-encoded CA bundle (hub cluster)"
          echo "   - ramen-dr-cluster-operator-config: Updated with base64-encoded CA bundle (managed clusters)"
          echo "   - Managed clusters: Certificate data distributed (includes ingress CAs)"
          echo ""
          echo "This follows Red Hat ODF Disaster Recovery certificate management guidelines"
          echo "for secure SSL access across clusters in the regional DR setup."
          echo "The ramen-hub-operator-config update enables SSL access for discovered applications"
          echo "as described in the Red Hat ODF Disaster Recovery documentation."
          }
          
          # Execute main function with retry logic
          while true; do
            if main_execution; then
              echo "üéâ Certificate extraction completed successfully!"
              exit 0
            else
              if [[ $RETRY_COUNT -lt $MAX_RETRIES ]]; then
                echo "üîÑ Main execution failed, retrying..."
                exponential_backoff
                continue
              else
                echo "üí• Max retries exceeded. Job will exit but ArgoCD can retry the sync."
                echo "   This is a temporary failure - the job will be retried on next ArgoCD sync."
                exit 1
              fi
            fi
          done
        env:
        - name: KUBECONFIG
          value: ""
      restartPolicy: Never
      serviceAccountName: odf-ssl-extractor-sa
  backoffLimit: 10
  activeDeadlineSeconds: 3600
  ttlSecondsAfterFinished: 300
