apiVersion: batch/v1
kind: Job
metadata:
  name: odf-ssl-certificate-extractor
  namespace: openshift-config
  labels:
    app.kubernetes.io/name: odf-ssl-certificate-management
    app.kubernetes.io/component: certificate-extraction
  annotations:
    argocd.argoproj.io/sync-wave: "1"
    argocd.argoproj.io/sync-options: Prune=false
    argocd.argoproj.io/compare-options: IgnoreExtraneous
spec:
  template:
    spec:
      containers:
      - name: odf-ssl-extractor
        image: registry.redhat.io/openshift4/ose-cli:latest
        resources:
          requests:
            memory: "512Mi"
            cpu: "200m"
          limits:
            memory: "1Gi"
            cpu: "500m"
        command:
        - /bin/bash
        - -c
        - |
          set -euo pipefail
          
          echo "Starting ODF SSL certificate extraction and distribution..."
          echo "Following Red Hat ODF Disaster Recovery certificate management guidelines"
          
          # Configuration for retry logic
          MAX_RETRIES=5
          BASE_DELAY=30
          MAX_DELAY=300
          RETRY_COUNT=0
          
          # Function to implement exponential backoff
          exponential_backoff() {
            local delay=$((BASE_DELAY * (2 ** RETRY_COUNT)))
            if [[ $delay -gt $MAX_DELAY ]]; then
              delay=$MAX_DELAY
            fi
            echo "‚è≥ Waiting $delay seconds before retry (attempt $((RETRY_COUNT + 1))/$MAX_RETRIES)..."
            sleep $delay
            ((RETRY_COUNT++))
          }
          
          # Function to handle errors gracefully
          handle_error() {
            local error_msg="$1"
            echo "‚ùå Error: $error_msg"
            
            if [[ $RETRY_COUNT -lt $MAX_RETRIES ]]; then
              echo "üîÑ Retrying in a moment..."
              exponential_backoff
              return 0
            else
              echo "üí• Max retries exceeded. Job will exit but ArgoCD can retry the sync."
              echo "   This is a temporary failure - the job will be retried on next ArgoCD sync."
              exit 1
            fi
          }
          
          # Main execution with retry logic
          main_execution() {
            # Create working directory
            WORK_DIR="/tmp/odf-ssl-certs"
            mkdir -p "$WORK_DIR"
          
          # Function to extract CA from cluster
          extract_cluster_ca() {
            cluster_name="$1"
            output_file="$2"
            kubeconfig="${3:-}"
            
            echo "Extracting CA from cluster: $cluster_name"
            
            if [[ -n "$kubeconfig" && -f "$kubeconfig" ]]; then
              # Use provided kubeconfig
              echo "  Using kubeconfig: $kubeconfig"
              if oc --kubeconfig="$kubeconfig" get configmap -n openshift-config-managed trusted-ca-bundle -o jsonpath="{.data['ca-bundle\.crt']}" > "$output_file" 2>/dev/null; then
                if [[ -s "$output_file" ]]; then
                  echo "  CA extracted from $cluster_name using kubeconfig"
                  return 0
                else
                  echo "  CA file is empty from $cluster_name"
                  return 1
                fi
              else
                echo "  Failed to get trusted-ca-bundle from $cluster_name"
                return 1
              fi
            else
              # Use current context (hub cluster)
              echo "  Using current context for hub cluster"
              if oc get configmap -n openshift-config-managed trusted-ca-bundle -o jsonpath="{.data['ca-bundle\.crt']}" > "$output_file" 2>/dev/null; then
                if [[ -s "$output_file" ]]; then
                  echo "  CA extracted from $cluster_name using current context"
                  return 0
                else
                  echo "  CA file is empty from $cluster_name"
                  return 1
                fi
              else
                echo "  Failed to get trusted-ca-bundle from $cluster_name"
                return 1
              fi
            fi
          }
          
          # Function to extract ingress CA from cluster
          extract_ingress_ca() {
            cluster_name="$1"
            output_file="$2"
            kubeconfig="${3:-}"
            
            echo "Extracting ingress CA from cluster: $cluster_name"
            
            if [[ -n "$kubeconfig" && -f "$kubeconfig" ]]; then
              # Use provided kubeconfig
              echo "  Using kubeconfig: $kubeconfig"
              # Try to get ingress CA from router-ca secret
              if oc --kubeconfig="$kubeconfig" get secret -n openshift-ingress-operator router-ca -o jsonpath='{.data.tls\.crt}' 2>/dev/null | base64 -d > "$output_file" 2>/dev/null; then
                if [[ -s "$output_file" ]]; then
                  echo "  Ingress CA extracted from $cluster_name using kubeconfig"
                  return 0
                fi
              fi
              # Fallback: try to get from ingress operator config
              if oc --kubeconfig="$kubeconfig" get secret -n openshift-ingress-operator router-ca -o jsonpath='{.data.ca\.crt}' 2>/dev/null | base64 -d > "$output_file" 2>/dev/null; then
                if [[ -s "$output_file" ]]; then
                  echo "  Ingress CA extracted from $cluster_name using kubeconfig (fallback)"
                  return 0
                fi
              fi
              echo "  Failed to get ingress CA from $cluster_name"
              return 1
            else
              # Use current context (hub cluster)
              echo "  Using current context for hub cluster"
              # Try to get ingress CA from router-ca secret
              if oc get secret -n openshift-ingress-operator router-ca -o jsonpath='{.data.tls\.crt}' 2>/dev/null | base64 -d > "$output_file" 2>/dev/null; then
                if [[ -s "$output_file" ]]; then
                  echo "  Ingress CA extracted from $cluster_name using current context"
                  return 0
                fi
              fi
              # Fallback: try to get from ingress operator config
              if oc get secret -n openshift-ingress-operator router-ca -o jsonpath='{.data.ca\.crt}' 2>/dev/null | base64 -d > "$output_file" 2>/dev/null; then
                if [[ -s "$output_file" ]]; then
                  echo "  Ingress CA extracted from $cluster_name using current context (fallback)"
                  return 0
                fi
              fi
              echo "  Failed to get ingress CA from $cluster_name"
              return 1
            fi
          }
          
          # Function to create combined CA bundle
          create_combined_ca_bundle() {
            output_file="$1"
            shift
            ca_files=("$@")
            
            echo "Creating combined CA bundle..."
            > "$output_file"
            
            file_count=0
            for ca_file in "${ca_files[@]}"; do
              if [[ -f "$ca_file" && -s "$ca_file" ]]; then
                echo "# CA from $(basename "$ca_file" .crt)" >> "$output_file"
                
                # Extract only the first few complete certificates to avoid size limits
                cert_count=0
                in_cert=false
                while IFS= read -r line; do
                  if [[ "$line" == "-----BEGIN CERTIFICATE-----" ]]; then
                    in_cert=true
                    cert_count=$((cert_count + 1))
                    if [[ $cert_count -gt 5 ]]; then
                      break
                    fi
                  fi
                  if [[ $in_cert == true ]]; then
                    echo "$line" >> "$output_file"
                  fi
                  if [[ "$line" == "-----END CERTIFICATE-----" ]]; then
                    in_cert=false
                    echo "" >> "$output_file"
                  fi
                done < "$ca_file"
                
                file_count=$((file_count + 1))
              fi
            done
            
            if [[ $file_count -gt 0 ]]; then
              echo "Combined CA bundle created with $file_count CA sources (first 5 certs each)"
              return 0
            else
              echo "No valid CA files found to combine"
              return 1
            fi
          }
          
          # Extract hub cluster CA
          echo "1. Extracting hub cluster CA..."
          if extract_cluster_ca "hub" "$WORK_DIR/hub-ca.crt"; then
            echo "  Hub cluster CA extracted successfully"
            echo "  Certificate size: $(wc -c < "$WORK_DIR/hub-ca.crt") bytes"
            echo "  First few lines:"
            head -n 5 "$WORK_DIR/hub-ca.crt"
          else
            echo "  Failed to extract hub cluster CA"
            echo "  Job will continue with managed cluster certificates only"
          fi
          
          # Extract hub cluster ingress CA
          echo "1b. Extracting hub cluster ingress CA..."
          if extract_ingress_ca "hub" "$WORK_DIR/hub-ingress-ca.crt"; then
            echo "  Hub cluster ingress CA extracted successfully"
            echo "  Certificate size: $(wc -c < "$WORK_DIR/hub-ingress-ca.crt") bytes"
          else
            echo "  Failed to extract hub cluster ingress CA"
            echo "  Job will continue without hub ingress CA"
          fi
          
          # Get managed clusters
          echo "2. Discovering managed clusters..."
          MANAGED_CLUSTERS=$(oc get managedclusters -o jsonpath='{.items[*].metadata.name}' 2>/dev/null || echo "")
          
          if [[ -z "$MANAGED_CLUSTERS" ]]; then
            echo "  No managed clusters found"
          else
            echo "  Found managed clusters: $MANAGED_CLUSTERS"
          fi
          
          # Extract CA from each managed cluster
          CA_FILES=()
          REQUIRED_CLUSTERS=("hub" "ocp-primary" "ocp-secondary")
          EXTRACTED_CLUSTERS=()
          
          # Track hub cluster CA extraction
          if [[ -f "$WORK_DIR/hub-ca.crt" && -s "$WORK_DIR/hub-ca.crt" ]]; then
            CA_FILES+=("$WORK_DIR/hub-ca.crt")
            EXTRACTED_CLUSTERS+=("hub")
            echo "  Added hub CA to bundle"
          else
            echo "  ‚ùå Hub CA not available - REQUIRED for DR setup"
          fi
          
          if [[ -f "$WORK_DIR/hub-ingress-ca.crt" && -s "$WORK_DIR/hub-ingress-ca.crt" ]]; then
            CA_FILES+=("$WORK_DIR/hub-ingress-ca.crt")
            echo "  Added hub ingress CA to bundle"
          else
            echo "  Hub ingress CA not available, continuing without it"
          fi
          
          index=1
          
          for cluster in $MANAGED_CLUSTERS; do
            if [[ "$cluster" == "local-cluster" ]]; then
              continue
            fi
            
            echo "3.$index Extracting CA from $cluster..."
            
            # Try to get kubeconfig for the cluster
            KUBECONFIG_FILE=""
            if oc get secret -n "$cluster" -o name | grep -E "(admin-kubeconfig|kubeconfig)" | head -1 | xargs -I {} oc get {} -n "$cluster" -o jsonpath='{.data.kubeconfig}' | base64 -d > "$WORK_DIR/${cluster}-kubeconfig.yaml" 2>/dev/null; then
              KUBECONFIG_FILE="$WORK_DIR/${cluster}-kubeconfig.yaml"
            fi
            
            cluster_ca_extracted=false
            if extract_cluster_ca "$cluster" "$WORK_DIR/${cluster}-ca.crt" "$KUBECONFIG_FILE"; then
              CA_FILES+=("$WORK_DIR/${cluster}-ca.crt")
              EXTRACTED_CLUSTERS+=("$cluster")
              cluster_ca_extracted=true
              echo "  Certificate size: $(wc -c < "$WORK_DIR/${cluster}-ca.crt") bytes"
            else
              echo "  ‚ùå Could not extract CA from $cluster - REQUIRED for DR setup"
            fi
            
            # Extract ingress CA from managed cluster
            echo "3b.$index Extracting ingress CA from $cluster..."
            if extract_ingress_ca "$cluster" "$WORK_DIR/${cluster}-ingress-ca.crt" "$KUBECONFIG_FILE"; then
              CA_FILES+=("$WORK_DIR/${cluster}-ingress-ca.crt")
              echo "  Ingress CA certificate size: $(wc -c < "$WORK_DIR/${cluster}-ingress-ca.crt") bytes"
            else
              echo "  Warning: Could not extract ingress CA from $cluster, continuing without it"
            fi
            
            ((index++))
          done
          
          # Validate that we have CA material from all required clusters
          echo "4. Validating CA extraction from required clusters..."
          MISSING_CLUSTERS=()
          for required_cluster in "${REQUIRED_CLUSTERS[@]}"; do
            if [[ " ${EXTRACTED_CLUSTERS[@]} " =~ " ${required_cluster} " ]]; then
              echo "  ‚úÖ CA extracted from $required_cluster"
            else
              echo "  ‚ùå CA NOT extracted from $required_cluster"
              MISSING_CLUSTERS+=("$required_cluster")
            fi
          done
          
          if [[ ${#MISSING_CLUSTERS[@]} -gt 0 ]]; then
            echo ""
            echo "‚ùå CRITICAL ERROR: CA material missing from required clusters:"
            for missing in "${MISSING_CLUSTERS[@]}"; do
              echo "   - $missing"
            done
            echo ""
            echo "The ODF SSL certificate extractor job requires CA material from ALL three clusters:"
            echo "   - hub (hub cluster)"
            echo "   - ocp-primary (primary managed cluster)"  
            echo "   - ocp-secondary (secondary managed cluster)"
            echo ""
            echo "Without CA material from all clusters, the DR setup will fail."
            echo "Please ensure all clusters are accessible and have proper kubeconfigs."
            echo ""
            echo "Job will exit with error code 1."
            exit 1
          fi
          
          # Create combined CA bundle
          echo "5. Creating combined CA bundle..."
          echo "  CA files to combine: ${#CA_FILES[@]} files"
          for ca_file in "${CA_FILES[@]}"; do
            echo "    - $(basename "$ca_file") ($(wc -c < "$ca_file") bytes)"
          done
          
          if create_combined_ca_bundle "$WORK_DIR/combined-ca-bundle.crt" "${CA_FILES[@]}"; then
            echo "  Combined CA bundle created successfully"
            echo "  Bundle size: $(wc -c < "$WORK_DIR/combined-ca-bundle.crt") bytes"
            echo "  First few lines of bundle:"
            head -n 10 "$WORK_DIR/combined-ca-bundle.crt"
          else
            echo "  Failed to create combined CA bundle - no certificates extracted"
            echo "  Job will exit as no certificate data is available"
            exit 1
          fi
          
          # Create or update ConfigMap on hub cluster
          echo "6. Creating/updating cluster-proxy-ca-bundle ConfigMap on hub cluster..."
          
          # Check if ConfigMap exists
          if oc get configmap cluster-proxy-ca-bundle -n openshift-config >/dev/null 2>&1; then
            echo "  ConfigMap exists, patching with certificate data..."
            # Create a temporary patch file to avoid JSON escaping issues
            echo "data:" > "$WORK_DIR/patch.yaml"
            echo "  ca-bundle.crt: |" >> "$WORK_DIR/patch.yaml"
            cat "$WORK_DIR/combined-ca-bundle.crt" | sed 's/^/    /' >> "$WORK_DIR/patch.yaml"
            oc patch configmap cluster-proxy-ca-bundle -n openshift-config \
              --type=merge \
              --patch-file="$WORK_DIR/patch.yaml"
            rm -f "$WORK_DIR/patch.yaml"
          else
            echo "  ConfigMap does not exist, creating with certificate data..."
            oc create configmap cluster-proxy-ca-bundle \
              --from-file=ca-bundle.crt="$WORK_DIR/combined-ca-bundle.crt" \
              -n openshift-config
          fi
          
          echo "  ConfigMap created/updated successfully with certificate data"
          echo "  Certificate bundle contains CA certificates from hub and managed clusters"
          
          # Update hub cluster proxy
          echo "7. Updating hub cluster proxy configuration..."
          oc patch proxy/cluster --type=merge --patch='{"spec":{"trustedCA":{"name":"cluster-proxy-ca-bundle"}}}' || {
            echo "  Warning: Could not update hub cluster proxy"
          }
          
          # Restart ramenddr-cluster-operator pods on managed clusters before updating configmap
          echo "7a. Restarting ramenddr-cluster-operator pods on managed clusters..."
          
          for cluster in $MANAGED_CLUSTERS; do
            if [[ "$cluster" == "local-cluster" ]]; then
              continue
            fi
            
            echo "  Processing cluster: $cluster"
            
            # Get kubeconfig for the cluster
            KUBECONFIG_FILE=""
            if oc get secret -n "$cluster" -o name | grep -E "(admin-kubeconfig|kubeconfig)" | head -1 | xargs -I {} oc get {} -n "$cluster" -o jsonpath='{.data.kubeconfig}' | base64 -d > "$WORK_DIR/${cluster}-kubeconfig.yaml" 2>/dev/null; then
              KUBECONFIG_FILE="$WORK_DIR/${cluster}-kubeconfig.yaml"
            fi
            
            if [[ -n "$KUBECONFIG_FILE" && -f "$KUBECONFIG_FILE" ]]; then
              # Find ramenddr-cluster-operator pods
              RAMEN_PODS=$(oc --kubeconfig="$KUBECONFIG_FILE" get pods -n openshift-dr-system -l app=ramenddr-cluster-operator -o jsonpath='{.items[*].metadata.name}' 2>/dev/null || echo "")
              
              if [[ -n "$RAMEN_PODS" ]]; then
                echo "    Found ramenddr-cluster-operator pods: $RAMEN_PODS"
                
                for pod in $RAMEN_PODS; do
                  echo "    Deleting pod $pod to trigger restart..."
                  oc --kubeconfig="$KUBECONFIG_FILE" delete pod "$pod" -n openshift-dr-system --ignore-not-found=true || {
                    echo "    Warning: Could not delete pod $pod"
                  }
                done
                
                # Wait for pods to be deleted
                echo "    Waiting for pods to be terminated..."
                for pod in $RAMEN_PODS; do
                  oc --kubeconfig="$KUBECONFIG_FILE" wait --for=delete pod/"$pod" -n openshift-dr-system --timeout=60s 2>/dev/null || true
                done
                
                # Wait for new pods to be running
                echo "    Waiting for new ramenddr-cluster-operator pods to be running..."
                MAX_WAIT_ATTEMPTS=30
                WAIT_INTERVAL=10
                attempt=0
                
                while [[ $attempt -lt $MAX_WAIT_ATTEMPTS ]]; do
                  attempt=$((attempt + 1))
                  
                  NEW_PODS=$(oc --kubeconfig="$KUBECONFIG_FILE" get pods -n openshift-dr-system -l app=ramenddr-cluster-operator -o jsonpath='{.items[*].metadata.name}' 2>/dev/null || echo "")
                  ALL_RUNNING=true
                  
                  if [[ -n "$NEW_PODS" ]]; then
                    for pod in $NEW_PODS; do
                      POD_STATUS=$(oc --kubeconfig="$KUBECONFIG_FILE" get pod "$pod" -n openshift-dr-system -o jsonpath='{.status.phase}' 2>/dev/null || echo "Unknown")
                      
                      if [[ "$POD_STATUS" != "Running" ]]; then
                        ALL_RUNNING=false
                        break
                      fi
                    done
                    
                    if [[ "$ALL_RUNNING" == "true" ]]; then
                      echo "    ‚úÖ All ramenddr-cluster-operator pods are running on $cluster: $NEW_PODS"
                      break
                    else
                      echo "    ‚è≥ Waiting for pods to be running (attempt $attempt/$MAX_WAIT_ATTEMPTS)"
                    fi
                  else
                    echo "    ‚è≥ Waiting for pods to appear (attempt $attempt/$MAX_WAIT_ATTEMPTS)"
                  fi
                  
                  if [[ $attempt -lt $MAX_WAIT_ATTEMPTS ]]; then
                    sleep $WAIT_INTERVAL
                  fi
                done
                
                if [[ $attempt -ge $MAX_WAIT_ATTEMPTS ]]; then
                  echo "    ‚ö†Ô∏è  Warning: ramenddr-cluster-operator pods did not become ready within expected time on $cluster"
                  echo "     The pods may still be starting - configuration changes will be applied when ready"
                fi
              else
                echo "    ‚ö†Ô∏è  Warning: ramenddr-cluster-operator pods not found on $cluster - they may not be deployed yet"
                echo "     Configuration changes will be applied when the pods start"
              fi
            else
              echo "    ‚ùå Could not get kubeconfig for $cluster - skipping pod restart"
            fi
          done
          
          echo "  ‚úÖ Completed ramenddr-cluster-operator pod restarts on managed clusters"
          
          # Update ramen-hub-operator-config with base64-encoded CA bundle
          echo "7b. Updating ramen-hub-operator-config in openshift-operators namespace..."
          
          # Base64 encode the combined CA bundle
          CA_BUNDLE_BASE64=$(base64 -w 0 < "$WORK_DIR/combined-ca-bundle.crt" 2>/dev/null || base64 < "$WORK_DIR/combined-ca-bundle.crt" | tr -d '\n')
          
          # Check if ramen-hub-operator-config exists
          if oc get configmap ramen-hub-operator-config -n openshift-operators &>/dev/null; then
            echo "  ConfigMap exists, updating ramen_manager_config.yaml with caCertificates in s3StoreProfiles..."
            
            # Get existing ramen_manager_config.yaml content
            EXISTING_YAML=$(oc get configmap ramen-hub-operator-config -n openshift-operators -o jsonpath='{.data.ramen_manager_config\.yaml}' 2>/dev/null || echo "")
            
            # Create updated YAML with caCertificates in each s3StoreProfiles item
            if [[ -n "$EXISTING_YAML" ]]; then
              # Create a temporary YAML file with the update
              echo "$EXISTING_YAML" > "$WORK_DIR/existing-ramen-config.yaml"
              
              # Use yq to update caCertificates in each s3StoreProfiles item
              if command -v yq &>/dev/null; then
                # Update caCertificates for each item in s3StoreProfiles array
                yq eval ".s3StoreProfiles[]?.caCertificates = \"$CA_BUNDLE_BASE64\"" -i "$WORK_DIR/existing-ramen-config.yaml" 2>/dev/null || {
                  echo "  Warning: Could not update s3StoreProfiles with yq, trying alternative approach..."
                  # Fallback: manually add caCertificates to each profile
                  python3 -c "
import yaml
import sys

with open('$WORK_DIR/existing-ramen-config.yaml', 'r') as f:
    config = yaml.safe_load(f) or {}

if 's3StoreProfiles' not in config:
    config['s3StoreProfiles'] = []

for profile in config.get('s3StoreProfiles', []):
    profile['caCertificates'] = '$CA_BUNDLE_BASE64'

with open('$WORK_DIR/existing-ramen-config.yaml', 'w') as f:
    yaml.dump(config, f, default_flow_style=False, sort_keys=False)
" 2>/dev/null || {
                    echo "  Warning: Python/yaml not available, using sed fallback..."
                    # Very basic sed fallback - add caCertificates after each profile name
                    sed -i "/^  - name:/a\    caCertificates: \"$CA_BUNDLE_BASE64\"" "$WORK_DIR/existing-ramen-config.yaml" 2>/dev/null || true
                  }
                }
              else
                # Fallback: use Python if available
                if command -v python3 &>/dev/null; then
                  python3 -c "
import yaml
import sys

with open('$WORK_DIR/existing-ramen-config.yaml', 'r') as f:
    config = yaml.safe_load(f) or {}

if 's3StoreProfiles' not in config:
    config['s3StoreProfiles'] = []

for profile in config.get('s3StoreProfiles', []):
    profile['caCertificates'] = '$CA_BUNDLE_BASE64'

with open('$WORK_DIR/existing-ramen-config.yaml', 'w') as f:
    yaml.dump(config, f, default_flow_style=False, sort_keys=False)
" 2>/dev/null || {
                    echo "  Warning: Python yaml module not available, using sed fallback..."
                    # Very basic sed fallback
                    sed -i "/^  - name:/a\    caCertificates: \"$CA_BUNDLE_BASE64\"" "$WORK_DIR/existing-ramen-config.yaml" 2>/dev/null || true
                  }
                else
                  echo "  Error: yq or python3 not available - cannot update s3StoreProfiles"
                  echo "  Manual intervention required"
                fi
              fi
              
              UPDATED_YAML=$(cat "$WORK_DIR/existing-ramen-config.yaml")
            else
              # No existing YAML, create new one with s3StoreProfiles containing caCertificates
              UPDATED_YAML="s3StoreProfiles:
  - name: default
    caCertificates: \"$CA_BUNDLE_BASE64\""
            fi
            
            # Create patch file for ConfigMap update
            echo "data:" > "$WORK_DIR/ramen-patch.yaml"
            echo "  ramen_manager_config.yaml: |" >> "$WORK_DIR/ramen-patch.yaml"
            echo "$UPDATED_YAML" | sed 's/^/    /' >> "$WORK_DIR/ramen-patch.yaml"
            
            # Patch the ConfigMap with updated YAML
            if oc patch configmap ramen-hub-operator-config -n openshift-operators \
              --type=merge \
              --patch-file="$WORK_DIR/ramen-patch.yaml" 2>&1; then
              
              # Verify the patch was successful
              sleep 2
              VERIFIED_YAML=$(oc get configmap ramen-hub-operator-config -n openshift-operators -o jsonpath='{.data.ramen_manager_config\.yaml}' 2>/dev/null || echo "")
              
              if echo "$VERIFIED_YAML" | grep -q "s3StoreProfiles" && echo "$VERIFIED_YAML" | grep -q "caCertificates" && echo "$VERIFIED_YAML" | grep -q "$CA_BUNDLE_BASE64"; then
                echo "  ‚úÖ ramen-hub-operator-config updated and verified successfully"
                echo "     caCertificates added to all s3StoreProfiles items"
              else
                echo "  ‚ö†Ô∏è  Warning: ramen-hub-operator-config patched but verification failed"
                echo "     The caCertificates field may not have been set correctly in s3StoreProfiles"
                echo "     Current YAML content (first 10 lines):"
                echo "$VERIFIED_YAML" | head -n 10
              fi
            else
              echo "  ‚ùå Error: Could not patch ramen-hub-operator-config"
              echo "     Attempting alternative approach using oc apply..."
              
              # Alternative: Use oc apply with the patch file
              if oc apply -f "$WORK_DIR/ramen-patch.yaml" 2>&1; then
                sleep 2
                VERIFIED_YAML=$(oc get configmap ramen-hub-operator-config -n openshift-operators -o jsonpath='{.data.ramen_manager_config\.yaml}' 2>/dev/null || echo "")
                
                if echo "$VERIFIED_YAML" | grep -q "s3StoreProfiles" && echo "$VERIFIED_YAML" | grep -q "caCertificates" && echo "$VERIFIED_YAML" | grep -q "$CA_BUNDLE_BASE64"; then
                  echo "  ‚úÖ ramen-hub-operator-config updated using alternative approach"
                else
                  echo "  ‚ö†Ô∏è  Warning: Alternative approach applied but verification failed"
                fi
              else
                echo "  ‚ùå Alternative approach also failed"
                echo "     Manual intervention may be required to set caCertificates in s3StoreProfiles"
              fi
            fi
            
            rm -f "$WORK_DIR/existing-ramen-config.yaml" "$WORK_DIR/ramen-patch.yaml"
            
          else
            echo "  ConfigMap does not exist, creating with ramen_manager_config.yaml containing s3StoreProfiles with caCertificates..."
            oc create configmap ramen-hub-operator-config -n openshift-operators \
              --from-literal=ramen_manager_config.yaml="s3StoreProfiles:
  - name: default
    caCertificates: \"$CA_BUNDLE_BASE64\"" || {
              echo "  Warning: Could not create ramen-hub-operator-config"
            }
          fi
          
          echo "  ramen-hub-operator-config updated successfully with base64-encoded CA bundle in s3StoreProfiles"
          echo "  This enables SSL access for discovered applications in ODF Disaster Recovery"
          
          # Restart Velero pods on managed clusters to pick up new CA certificates
          echo "7c. Restarting Velero pods on managed clusters..."
          
          for cluster in $MANAGED_CLUSTERS; do
            if [[ "$cluster" == "local-cluster" ]]; then
              continue
            fi
            
            echo "  Processing cluster: $cluster"
            
            # Get kubeconfig for the cluster
            KUBECONFIG_FILE="$WORK_DIR/${cluster}-kubeconfig.yaml"
            if [[ ! -f "$KUBECONFIG_FILE" ]]; then
              # Fetch kubeconfig if not already available
              if oc get secret -n "$cluster" -o name | grep -E "(admin-kubeconfig|kubeconfig)" | head -1 | xargs -I {} oc get {} -n "$cluster" -o jsonpath='{.data.kubeconfig}' | base64 -d > "$KUBECONFIG_FILE" 2>/dev/null; then
                echo "    Fetched kubeconfig for $cluster"
              else
                echo "    ‚ùå Could not get kubeconfig for $cluster - skipping Velero pod restart"
                continue
              fi
            fi
            
            # Find Velero pods in openshift-adp namespace
            VELERO_PODS=$(oc --kubeconfig="$KUBECONFIG_FILE" get pods -n openshift-adp -l component=velero -o jsonpath='{.items[*].metadata.name}' 2>/dev/null || echo "")
            
            if [[ -n "$VELERO_PODS" ]]; then
                echo "    Found Velero pods: $VELERO_PODS"
                
                for pod in $VELERO_PODS; do
                  echo "    Deleting pod $pod to trigger restart..."
                  oc --kubeconfig="$KUBECONFIG_FILE" delete pod "$pod" -n openshift-adp --ignore-not-found=true || {
                    echo "    Warning: Could not delete pod $pod"
                  }
                done
                
                # Wait for pods to be deleted
                echo "    Waiting for pods to be terminated..."
                for pod in $VELERO_PODS; do
                  oc --kubeconfig="$KUBECONFIG_FILE" wait --for=delete pod/"$pod" -n openshift-adp --timeout=60s 2>/dev/null || true
                done
                
                # Wait for new pods to be running
                echo "    Waiting for new Velero pods to be running..."
                MAX_WAIT_ATTEMPTS=30
                WAIT_INTERVAL=10
                attempt=0
                
                while [[ $attempt -lt $MAX_WAIT_ATTEMPTS ]]; do
                  attempt=$((attempt + 1))
                  
                  NEW_PODS=$(oc --kubeconfig="$KUBECONFIG_FILE" get pods -n openshift-adp -l component=velero -o jsonpath='{.items[*].metadata.name}' 2>/dev/null || echo "")
                  ALL_RUNNING=true
                  
                  if [[ -n "$NEW_PODS" ]]; then
                    for pod in $NEW_PODS; do
                      POD_STATUS=$(oc --kubeconfig="$KUBECONFIG_FILE" get pod "$pod" -n openshift-adp -o jsonpath='{.status.phase}' 2>/dev/null || echo "Unknown")
                      
                      if [[ "$POD_STATUS" != "Running" ]]; then
                        ALL_RUNNING=false
                        break
                      fi
                    done
                    
                    if [[ "$ALL_RUNNING" == "true" ]]; then
                      echo "    ‚úÖ All Velero pods are running on $cluster: $NEW_PODS"
                      break
                    else
                      echo "    ‚è≥ Waiting for pods to be running (attempt $attempt/$MAX_WAIT_ATTEMPTS)"
                    fi
                  else
                    echo "    ‚è≥ Waiting for pods to appear (attempt $attempt/$MAX_WAIT_ATTEMPTS)"
                  fi
                  
                  if [[ $attempt -lt $MAX_WAIT_ATTEMPTS ]]; then
                    sleep $WAIT_INTERVAL
                  fi
                done
                
                if [[ $attempt -ge $MAX_WAIT_ATTEMPTS ]]; then
                  echo "    ‚ö†Ô∏è  Warning: Velero pods did not become ready within expected time on $cluster"
                  echo "     The pods may still be starting - new CA certificates will be applied when ready"
                fi
              else
                echo "    ‚ö†Ô∏è  Warning: Velero pods not found on $cluster - they may not be deployed yet"
                echo "     New CA certificates will be applied when the pods start"
              fi
          done
          
          echo "  ‚úÖ Completed Velero pod restarts on managed clusters"
          
          # Distribute certificate data to managed clusters with retry logic
          echo "8. Distributing certificate data to managed clusters..."
          DISTRIBUTION_ATTEMPTS=3
          DISTRIBUTION_SLEEP=10
          
          for cluster in $MANAGED_CLUSTERS; do
            if [[ "$cluster" == "local-cluster" ]]; then
              continue
            fi
            
            echo "  Distributing to $cluster..."
            
            # Get kubeconfig for the cluster
            KUBECONFIG_FILE=""
            if oc get secret -n "$cluster" -o name | grep -E "(admin-kubeconfig|kubeconfig)" | head -1 | xargs -I {} oc get {} -n "$cluster" -o jsonpath='{.data.kubeconfig}' | base64 -d > "$WORK_DIR/${cluster}-kubeconfig.yaml" 2>/dev/null; then
              KUBECONFIG_FILE="$WORK_DIR/${cluster}-kubeconfig.yaml"
            fi
            
            if [[ -n "$KUBECONFIG_FILE" && -f "$KUBECONFIG_FILE" ]]; then
              # Retry distribution to managed cluster
              distribution_success=false
              for dist_attempt in $(seq 1 $DISTRIBUTION_ATTEMPTS); do
                echo "    Distribution attempt $dist_attempt/$DISTRIBUTION_ATTEMPTS for $cluster..."
                
                # Create ConfigMap on managed cluster
                if oc --kubeconfig="$KUBECONFIG_FILE" create configmap cluster-proxy-ca-bundle \
                  --from-file=ca-bundle.crt="$WORK_DIR/combined-ca-bundle.crt" \
                  -n openshift-config \
                  --dry-run=client -o yaml | oc --kubeconfig="$KUBECONFIG_FILE" apply -f -; then
                  
                  # Update managed cluster proxy
                  if oc --kubeconfig="$KUBECONFIG_FILE" patch proxy/cluster --type=merge --patch='{"spec":{"trustedCA":{"name":"cluster-proxy-ca-bundle"}}}'; then
                    echo "    ‚úÖ Certificate data distributed to $cluster (attempt $dist_attempt)"
                    distribution_success=true
                    break
                  else
                    echo "    ‚ö†Ô∏è  ConfigMap created but proxy update failed for $cluster (attempt $dist_attempt)"
                  fi
                else
                  echo "    ‚ö†Ô∏è  ConfigMap creation failed for $cluster (attempt $dist_attempt)"
                fi
                
                if [[ $dist_attempt -lt $DISTRIBUTION_ATTEMPTS ]]; then
                  echo "    ‚è≥ Waiting $DISTRIBUTION_SLEEP seconds before retry..."
                  sleep $DISTRIBUTION_SLEEP
                fi
              done
              
              if [[ "$distribution_success" != "true" ]]; then
                echo "    ‚ùå Failed to distribute certificate data to $cluster after $DISTRIBUTION_ATTEMPTS attempts"
                echo "    This may cause DR prerequisites check to fail"
              fi
            else
              echo "    ‚ùå Could not get kubeconfig for $cluster - skipping distribution"
            fi
          done
          
          # Verify distribution to managed clusters
          echo "9. Verifying certificate distribution to managed clusters..."
          verification_failed=false
          REQUIRED_VERIFICATION_CLUSTERS=("ocp-primary" "ocp-secondary")
          VERIFIED_CLUSTERS=()
          
          for cluster in $MANAGED_CLUSTERS; do
            if [[ "$cluster" == "local-cluster" ]]; then
              continue
            fi
            
            echo "  Verifying distribution to $cluster..."
            KUBECONFIG_FILE="$WORK_DIR/${cluster}-kubeconfig.yaml"
            
            if [[ -f "$KUBECONFIG_FILE" ]]; then
              # Check if ConfigMap exists and has content
              configmap_exists=$(oc --kubeconfig="$KUBECONFIG_FILE" get configmap cluster-proxy-ca-bundle -n openshift-config &>/dev/null && echo "true" || echo "false")
              configmap_size=$(oc --kubeconfig="$KUBECONFIG_FILE" get configmap cluster-proxy-ca-bundle -n openshift-config -o jsonpath='{.data.ca-bundle\.crt}' 2>/dev/null | wc -c || echo "0")
              proxy_configured=$(oc --kubeconfig="$KUBECONFIG_FILE" get proxy cluster -o jsonpath='{.spec.trustedCA.name}' 2>/dev/null || echo "")
              
              if [[ "$configmap_exists" == "true" && $configmap_size -gt 100 && "$proxy_configured" == "cluster-proxy-ca-bundle" ]]; then
                echo "    ‚úÖ $cluster: ConfigMap exists (${configmap_size} bytes), proxy configured"
                VERIFIED_CLUSTERS+=("$cluster")
              else
                echo "    ‚ùå $cluster: ConfigMap verification failed"
                echo "      ConfigMap exists: $configmap_exists"
                echo "      ConfigMap size: $configmap_size bytes"
                echo "      Proxy configured: $proxy_configured"
                verification_failed=true
              fi
            else
              echo "    ‚ùå $cluster: No kubeconfig available for verification"
              verification_failed=true
            fi
          done
          
          # Check if all required clusters are verified
          echo "10. Validating verification results..."
          MISSING_VERIFICATION_CLUSTERS=()
          for required_cluster in "${REQUIRED_VERIFICATION_CLUSTERS[@]}"; do
            if [[ " ${VERIFIED_CLUSTERS[@]} " =~ " ${required_cluster} " ]]; then
              echo "  ‚úÖ $required_cluster: Certificate distribution verified"
            else
              echo "  ‚ùå $required_cluster: Certificate distribution NOT verified"
              MISSING_VERIFICATION_CLUSTERS+=("$required_cluster")
            fi
          done
          
          if [[ ${#MISSING_VERIFICATION_CLUSTERS[@]} -gt 0 ]]; then
            echo ""
            echo "‚ùå CRITICAL ERROR: Certificate distribution verification failed for required clusters:"
            for missing in "${MISSING_VERIFICATION_CLUSTERS[@]}"; do
              echo "   - $missing"
            done
            echo ""
            echo "The ODF SSL certificate extractor job requires successful certificate distribution"
            echo "to ALL managed clusters (ocp-primary and ocp-secondary)."
            echo ""
            echo "Without proper certificate distribution, the DR setup will fail."
            echo "Please check cluster connectivity and kubeconfig availability."
            echo ""
            echo "Job will exit with error code 1."
            exit 1
          fi
          
          if [[ "$verification_failed" == "true" ]]; then
            echo ""
            echo "‚ö†Ô∏è  Certificate distribution verification failed for some clusters"
            echo "   This may cause DR prerequisites check to fail"
            echo "   Manual intervention may be required"
            echo ""
            echo "Job will exit with error code 1."
            exit 1
          else
            echo ""
            echo "‚úÖ All managed clusters verified successfully"
          fi
          
          echo ""
          echo "‚úÖ ODF SSL certificate management completed successfully!"
          echo "   - Hub cluster CA bundle: Updated (includes trusted CA + ingress CA)"
          echo "   - Hub cluster proxy: Configured"
          echo "   - Managed clusters: ramenddr-cluster-operator pods restarted"
          echo "   - ramen-hub-operator-config: Updated with base64-encoded CA bundle in s3StoreProfiles (hub cluster)"
          echo "   - Managed clusters: Velero pods restarted (openshift-adp namespace)"
          echo "   - Managed clusters: Certificate data distributed (includes ingress CAs)"
          echo ""
          echo "This follows Red Hat ODF Disaster Recovery certificate management guidelines"
          echo "for secure SSL access across clusters in the regional DR setup."
          echo "The ramen-hub-operator-config update enables SSL access for discovered applications"
          echo "as described in the Red Hat ODF Disaster Recovery documentation."
          }
          
          # Execute main function with retry logic
          while true; do
            if main_execution; then
              echo "üéâ Certificate extraction completed successfully!"
              exit 0
            else
              if [[ $RETRY_COUNT -lt $MAX_RETRIES ]]; then
                echo "üîÑ Main execution failed, retrying..."
                exponential_backoff
                continue
              else
                echo "üí• Max retries exceeded. Job will exit but ArgoCD can retry the sync."
                echo "   This is a temporary failure - the job will be retried on next ArgoCD sync."
                exit 1
              fi
            fi
          done
        env:
        - name: KUBECONFIG
          value: ""
      restartPolicy: Never
      serviceAccountName: odf-ssl-extractor-sa
  backoffLimit: 10
  activeDeadlineSeconds: 3600
  ttlSecondsAfterFinished: 300
